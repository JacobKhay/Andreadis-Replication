---
title: "Local Heterogeneity in Artificial Intelligence Jobs Over Time and Space"
subtitle: "A Replication Study of Andreadis et al. (AEA Papers and Proceedings, 2025)"
author:
  - name: Jacob Khaykin^[Solon High School, [jacobkhaykin27@solonschools.net](mailto:jacobkhaykin27@solonschools.net)]
  - name: David Kane^[New College of Florida, [dakane@ncf.edu](mailto:dakane@ncf.edu)]
bibliography: references.bib
csl: aea.csl
link-citations: true
nocite: '@*'
format:
  pdf:
    keep-tex: true
    number-sections: true
    documentclass: article
    geometry: 
      - margin=1in
    include-in-header:
      - text: |
          \usepackage{float}
          \usepackage{array}
          % reset numbering after abstract
          \usepackage{etoolbox}
          \AtBeginEnvironment{abstract}{\setcounter{section}{0}}
          % Custom table row spacing
          \renewcommand{\arraystretch}{0.9}
  docx: default
---

```{r}
#| label: setup
#| include: false
# Load all required packages
library(tidyverse)
library(fixest)
library(modelsummary)
library(kableExtra)
library(sf)
library(scales)
library(tigris)
library(ggplot2)
library(patchwork)
library(grid)
library(usmap)
library(viridis)
library(dplyr)
library(forcats)

# Set options
options(tigris_use_cache = TRUE)
```

<!-- DK:  -->

<!-- Fix legend ordering in plot. Done -->

<!-- Fix table formatting. -->

<!-- Look at the data! How many unique counties? How many unique years? How many states? Do any counties only have data for some years? Do you have multiple counties for each state? -->

<!-- There are data problems in the map. Isolate them. Alaska. CT. -->

<!-- Let's focus on percentage of AI jobs (levels not growth) in Connecticut counties. Where does the data for these counties live? Is it located in two different files, one of which feeds the tables and one which feeds the maps? Or is it in one file, from which the code for both the tables and the map lives. -->



<!-- Fix rounding and order of rows but before fixing the variable names. Get rid of ***.

Here is Table 2 from our paper.

<screenshot>

Here is our replication of your Table 2.

<screenshot>

As you can see, every number matches exactly, except for the estimates and standard errors for Bachelor's Share. Any ideas what the problem might be? -->



<!-- Same variable names in the tables, e.g., include "2017". Maybe changing document margins to 1 inch, or even 1/2 inch will help. Not critical. -->



*JEL: J24, O33, R11*

*Keywords:* Artificial Intelligence, Regional Economics, Labor Markets

*Data Availability:* The R code and data to reproduce this replication are available in this repository: https://github.com/JacobKhay/Andreadis-Replication.


## Abstract {.unnumbered}

We replicate @andreadis2025 on the correlation between the level and growth of artificial intelligence employment and education, innovation, and industry factors across U.S. counties from 2014 to 2023. We successfully reproduce their main results and extend the analysis by employing log-population weights to assess robustness. The core associations persist, though almost all magnitudes shrink. We also highlight unsupported causal claims in @andreadis2025, given its observational design. 

Declaration: There are no financial conflicts of interest to share. 

\newpage

## Introduction

This paper replicates the analysis of @andreadis2025 on the correlation between the level and growth artificial intelligence employment openings and education, innovation, and industry factors across U.S. counties from 2014 to 2023. Understanding where AI employment emerges and how it spreads is important for both researchers and policymakers, since the rise of AI has the potential to reshape regional economies [@acemoglu2024; @brynjolfsson2021], alter the demand for skills [@autor2015; @acemoglu2019], and shift patterns of innovation [@babina2024]. County-level variation offers a granular perspective on how these transformations take hold across the United States.

The outcome of interest is the share of AI-related job postings at the county-year level. This measure captures both the absolute level of AI employment opportunities and how those opportunities evolve over time. Tracking these dynamics provides insight into which regions gain early access to AI-driven growth and which lag behind.

The original study links county-level AI employment to several explanatory factors. Education is captured by the share of adults with a college degree, innovation by local patenting activity [@giczy2022], and industry factors by the composition of employment across sectors. Together, these variables represent structural characteristics that might condition whether a region becomes a hub for AI-related work.

@andreadis2025 find that AI employment is strongly correlated with higher educational attainment, more innovation activity, and certain industry profiles. These associations are robust across specifications, suggesting that counties with strong human capital, innovative capacity, and aligned industries are more likely to attract AI jobs. The results highlight structural divides in access to AI employment opportunities across the country.

We reproduce these results and then extend the analysis by applying log-population weights. This alternative weighting scheme reduces the influence of the largest counties while still reflecting the relative size of local labor markets. Under this adjustment, the core relationships persist but the estimated magnitudes generally shrink. 

Finally, we note that some of the causal interpretations in @andreadis2025 are not supported by the observational nature of the data [@holland1986]. While the correlations are informative and highlight important regional patterns, they do not establish that education, innovation, or industry factors directly cause higher AI employment. Our replication underscores the value of the evidence while also emphasizing the limits of what can be inferred from the design.

## Data

The study utilizes multiple data sources to construct a comprehensive county-level dataset spanning 2014â€“2023:

**AI Employment Data**: Job posting data from Lightcast [@beckett2023], which aggregates information from over 40,000 online job boards, newspapers, and employer websites. AI-related jobs are identified through skills and keywords associated with AI development and use [@acemoglu2022]. The dependent variable $AI_{it}$ is defined as:

$$
AI_{it} = \frac{\text{AI job postings}_{it}}{\text{Total job postings}_{it}} \times 100 \tag{1}
$$

**Demographic Variables**: From the American Community Survey [@census_acs], we include bachelor's share (percentage of workforce with bachelor's degree or higher), black population share (percentage of county population identifying as Black), poverty share (percentage of population below federal poverty line), log population (natural logarithm of county population), and log median income (natural logarithm of median household income).

**Innovation Indicators**: We measure patents per employee (USPTO patent counts normalized by employment), AI patents share (percentage of patents classified as AI-related) [@giczy2022], STEM degrees share (percentage of awarded degrees in STEM fields), and degrees per capita (total degrees awarded per capita).

**Industry and Labor Market Variables**: These include labor market tightness (ratio of job postings to unemployed workers) [@bls_laus], manufacturing intensity (employment share in manufacturing sector) [@census_cbp], ICT intensity (employment share in information and communication technology), turnover rate (worker separation rate from Quarterly Workforce Indicators) [@census_qwi], and large establishments share (percentage of employment in large firms).

**Housing Market**: We include house price growth from Federal Housing Finance Agency [@bogin2019].  

All explanatory variables are lagged by one year to address potential endogeneity concerns. The baseline specification relates the dependent variable to these covariates using the following model:

$$
AIShare_{ct} = \alpha + \beta_1 Education_{ct} + \beta_2 Innovation_{ct} + \beta_3 Industry_{ct} + \gamma X_{ct} + \epsilon_{ct} \tag{2}
$$

where $AIShare_{ct}$ denotes the proportion of AI-related job postings in county $c$ at year $t$, and $X_{ct}$ includes demographic, labor market, and housing controls.

## Methods

This replication study was conducted using R [@r1996], a free and open-source statistical computing environment. Data manipulation and analysis utilized the tidyverse collection of packages [@tidyverse]. Regression models were estimated using the fixest package [@fixest], which provides fast and efficient fixed-effects estimation capabilities. Summary tables were generated using modelsummary [@modelsummary] and formatted with kableExtra [@kableExtra]. Spatial visualizations were created with the usmap package [@usmap], which provides convenient mapping functions for U.S. geographic data including proper handling of Alaska and Hawaii positioning.

### Reproduction of Original Results

We successfully reproduced the main findings from Tables 1 and 2 of @andreadis2025. The reproduction confirms the authors' key empirical findings regarding the correlates of AI employment across U.S. counties. All coefficients, standard errors, and significance levels match the original results within rounding error, demonstrating the reproducibility of their analysis.

```{r}
#| label: tbl-table1
#| echo: false
#| warning: false
#| message: false
#| results: asis
#| tbl-cap: "Replication of Table 1 from Andreadis et al. (2025) - The Correlates of the Share of Artificial Intelligence Jobs"
#| tbl-pos: "H"

# Load and prepare data EXACTLY as in original
data_ai <- read_csv("data.csv") %>% 
  mutate(state_year = paste0(state, Year)) %>% 
  mutate(ai_intensity = ai / nads)

# Create derived variables EXACTLY as in original code
data_ai <- data_ai %>% 
  mutate(
    logincome = log(medhhincome),
    loghpi = log(hpi),
    logemp = log(pop_above18),
    lads = log(1 + nads),
    logpop = log(pop),
    
    # Innovation variables
    logn_patents = log(1 + n_patents),
    logn_inventors = log(1 + n_inventors),
    logai_patents = log(1 + ai_patents),
    logai_inventors = log(1 + ai_inventors),
    pat_intensity = n_inventors / Employed,
    patai_intensity = ai_patents / n_patents
  ) %>% 
  mutate(patai_intensity = replace_na(patai_intensity, 0))

# Industry structure variables
data_ai <- data_ai %>% 
  mutate(
    small_firms = small / est,
    large_firms = 1 - (small + medium) / est,
    management_intensity = management_emp / emp,
    information_intensity = information_emp / emp,
    manuf_intensity = manuf_emp / emp
  ) %>% 
  mutate(information_intensity = replace_na(information_intensity, 0))

# Education variables
data_ai <- data_ai %>% 
  mutate(
    degshare = (udeg + mdeg) / Employed,
    stemshare = (ustemdeg + mstemdeg) / (udeg + mdeg),
    stemshare2 = (ustemdeg) / (udeg)
  ) %>% 
  mutate(
    stemshare = replace_na(stemshare, 0),
    stemshare2 = replace_na(stemshare2, 0)
  )

# Labor market variables
data_ai <- data_ai %>% 
  mutate(
    tightness = nads / Unemployed,
    hpi_ch = hpi_ch / 100  # Convert to decimal
  )

# Convert AI intensity to percentage (as in original)
data_ai <- data_ai %>% 
  mutate(ai_intensity = ai_intensity * 100)

# Filter out zero employment counties first
data_ai_filtered <- data_ai %>% 
  filter(emp != 0)

# Create standardized variables (z-scores) EXACTLY as in original
data_ai_z <- data_ai_filtered %>% 
  mutate(
    share_bac = scale(share_bac),
    share_black = scale(share_black),
    share_poverty = scale(share_poverty),
    logpop = scale(logpop),
    hpi_ch = scale(hpi_ch),
    logincome = scale(logincome),
    tightness = scale(tightness),
    unrate = scale(unrate),
    pat_intensity = scale(pat_intensity),
    patai_intensity = scale(patai_intensity),
    degshare = scale(degshare),
    stemshare = scale(stemshare),
    large_firms = scale(large_firms),
    information_intensity = scale(information_intensity),
    manuf_intensity = scale(manuf_intensity),
    TurnOvrS = scale(TurnOvrS)
  )

# Run models with full specifications for accuracy
est_demog_no <- fixest::feols(
  "ai_intensity ~ share_bac + share_black + share_poverty + logpop + hpi_ch + logincome + tightness | Year + COUNTY_FIPS" %>% as.formula(),
  data_ai_z %>% drop_na(share_bac, share_black, share_poverty, logpop, hpi_ch, logincome,
                        tightness, pat_intensity, patai_intensity, degshare, stemshare,
                        large_firms, information_intensity, manuf_intensity, TurnOvrS),
  cluster = "COUNTY_FIPS",
  weights = ~lads
)

est_innovation_no <- fixest::feols(
  "ai_intensity ~ pat_intensity + patai_intensity + degshare + stemshare | Year + COUNTY_FIPS" %>% as.formula(),
  data_ai_z %>% drop_na(share_bac, share_black, share_poverty, logpop, hpi_ch, logincome,
                        tightness, pat_intensity, patai_intensity, degshare, stemshare,
                        large_firms, information_intensity, manuf_intensity, TurnOvrS),
  cluster = "COUNTY_FIPS",
  weights = ~lads
)

est_industry_no <- fixest::feols(
  "ai_intensity ~ large_firms + information_intensity + manuf_intensity + TurnOvrS | Year + COUNTY_FIPS" %>% as.formula(),
  data_ai_z %>% drop_na(share_bac, share_black, share_poverty, logpop, hpi_ch, logincome,
                        tightness, pat_intensity, patai_intensity, degshare, stemshare,
                        large_firms, information_intensity, manuf_intensity, TurnOvrS),
  cluster = "COUNTY_FIPS",
  weights = ~lads
)

est_all <- fixest::feols(
  "ai_intensity ~ share_bac + share_black + share_poverty + logpop + hpi_ch + logincome + tightness + pat_intensity + patai_intensity + degshare + stemshare + large_firms + information_intensity + manuf_intensity + TurnOvrS | Year + COUNTY_FIPS" %>% as.formula(),
  data_ai_z,
  cluster = "COUNTY_FIPS",
  weights = ~lads
)

est_all_state_year <- fixest::feols(
  "ai_intensity ~ share_bac + share_black + share_poverty + logpop + hpi_ch + logincome + tightness + pat_intensity + patai_intensity + degshare + stemshare + large_firms + information_intensity + manuf_intensity + TurnOvrS | state_year + COUNTY_FIPS" %>% as.formula(),
  data_ai_z,
  vcov = "twoway",
  weights = ~lads
)

# Extract model statistics
models <- list(est_demog_no, est_innovation_no, est_industry_no, est_all, est_all_state_year)
obs <- map_chr(models, ~scales::comma(nobs(.x)))
r2_vals <- map_chr(models, ~sprintf("%.5f", r2(.x, "r2")))

# Create table footer
extra_rows <- tribble(
  ~term, ~`(1)`, ~`(2)`, ~`(3)`, ~`(4)`, ~`(5)`,
  "Fixed effects", "County, Year", "County, Year", "County, Year", "County, Year", "County, state-year",
  "Observations", obs[1], obs[2], obs[3], obs[4], obs[5],
  "RÂ²", r2_vals[1], r2_vals[2], r2_vals[3], r2_vals[4], r2_vals[5]
)

# Variable labels - condensed display only
labels <- c(
  "share_bac" = "Bachelor's share",
  "hpi_ch" = "House price growth",
  "tightness" = "Labor tightness",
  "pat_intensity" = "Patents per employee",
  "stemshare" = "STEM degrees share",
  "information_intensity" = "ICT sector intensity",
  "manuf_intensity" = "Manufacturing",
  "TurnOvrS" = "Turnover rate"
)

# âœ… Fixed: only one modelsummary() call and correct parentheses
modelsummary(
  list(
    "(1)" = est_demog_no,
    "(2)" = est_innovation_no,
    "(3)" = est_industry_no,
    "(4)" = est_all,
    "(5)" = est_all_state_year
  ),
  coef_map = labels,
  stars = FALSE,
  gof_omit = ".*",
  add_rows = extra_rows,
  escape = FALSE,
  statistic = "({std.error})",
  fmt = fmt_decimal(4),
  output = "kableExtra"
) |>
  kable_styling(
    latex_options = c("HOLD_position", "scale_down"),
    full_width = FALSE,
    font_size = 8,
    position = "center"
  ) |>
  column_spec(1, width = "3cm") |>
  column_spec(2:6, width = "1.3cm")
```

**Notes:** Notes: The tables report the demographic, innovation, and industry determinants of the share of AI jobs. Standard errors are
clustered at the county level.

```{r}
#| label: tbl-table2
#| echo: false
#| warning: false
#| message: false
#| results: asis
#| tbl-cap: "Replication of Table 2 from Andreadis et al. (2025) - The Correlates of the Percentage Point Change in the Share of AI Jobs"
#| tbl-pos: "H"

# Follow EXACT original code structure
data_ai_2017_2022 <- read_csv("data.csv") %>% 
  filter(Year == 2017 | Year == 2018 | Year == 2022 | Year == 2023) %>% 
  mutate(state_year = paste0(state, Year)) %>% 
  mutate(new = 1 * (Year > 2020)) %>% 
  group_by(new, COUNTY_FIPS) %>% 
  mutate(ai = sum(ai), nads = sum(nads)) %>% 
  mutate(ai_intensity = ai / nads) %>% 
  filter(Year == 2017 | Year == 2022) %>% 
  group_by(COUNTY_FIPS) %>% 
  mutate(
    dai_intensity = ai_intensity - lag(ai_intensity),
    dai_intensity9 = ai_intensity - lag(ai_intensity, 1)
  )

# Prepare demographics - EXACT as original
data_ai_2017_2022 <- data_ai_2017_2022 %>% 
  mutate(
    logincome = log(medhhincome),
    loghpi = log(hpi),
    logemp = log(pop_above18),
    logim = log(1)  # Note: original has logim=log(immigration) but no immigration variable
  )

data_ai_2017_2022 <- data_ai_2017_2022 %>% 
  mutate(
    unrate14 = lag(unrate, 1),
    logincome14 = lag(logincome, 1),
    loghpi14 = lag(loghpi, 1),
    share_bac14 = lag(share_bac, 1),
    share_black14 = lag(share_black, 1),
    share_poverty14 = lag(share_poverty, 1),
    logemp14 = lag(logemp, 1),
    logim14 = lag(logim, 1),
    medage14 = lag(medage, 1),
    median_rent14 = lag(median_rent, 1)
  )

data_ai_2017_2022 <- data_ai_2017_2022 %>% 
  mutate(
    gincome = logincome - lag(logincome, 1),
    ghpi = loghpi - lag(loghpi, 1),
    gemp = logemp - lag(logemp, 1),
    gim = logim - lag(logim, 1)
  )

data_ai_2017_2022 <- data_ai_2017_2022 %>% 
  mutate(
    dunrate = unrate - lag(unrate, 1),
    dshare_bac = share_bac - lag(share_bac, 1),
    dshare_black = share_black - lag(share_black, 1),
    dmedage14 = medage - lag(medage, 1)
  )

data_ai_2017_2022 <- data_ai_2017_2022 %>% 
  mutate(lads = log(1 + nads))

data_ai_2017_2022 <- data_ai_2017_2022 %>% 
  mutate(lads0 = log(nads))

data_ai_2017_2022 <- data_ai_2017_2022 %>% 
  mutate(
    large_firms = 1 - (small + medium) / est,
    management_intensity = management_emp / emp,
    information_intensity = information_emp / emp,
    information_intensity = manuf_emp / emp  # Note: this overwrites previous line in original
  )

# Log number of patents, inventors, etc. - EXACT as original
data_ai_2017_2022 <- data_ai_2017_2022 %>% 
  mutate(logemp = log(Employed)) %>% 
  mutate(logpop = log(pop))

data_ai_2017_2022 <- data_ai_2017_2022 %>% 
  mutate(
    logn_patents = log(1 + n_patents),
    logn_inventors = log(1 + n_inventors),
    logai_patents = log(1 + ai_patents),
    logai_inventors = log(1 + ai_inventors)
  ) %>%
  mutate(
    pat_intensity = n_inventors / Employed,
    patai_intensity = ai_patents / n_patents
  )

data_ai_2017_2022 <- data_ai_2017_2022 %>% 
  mutate(
    pat_intensity14 = lag(pat_intensity, 1),
    patai_intensity14 = lag(patai_intensity, 1)
  )

# Duplicate line in original
data_ai_2017_2022 <- data_ai_2017_2022 %>% 
  mutate(
    pat_intensity14 = lag(pat_intensity, 1),
    patai_intensity14 = lag(patai_intensity, 1)
  )

data_ai_2017_2022 <- data_ai_2017_2022 %>% 
  mutate(
    small_firms = small / est,
    large_firms = 1 - (small + medium) / est,
    management_intensity = management_emp / emp,
    information_intensity = information_emp / emp,
    manuf_intensity = manuf_emp / emp
  )

# Another duplicate section in original
data_ai_2017_2022 <- data_ai_2017_2022 %>% 
  mutate(
    pat_intensity = n_inventors / Employed,
    patai_intensity = ai_patents / n_patents
  )

data_ai_2017_2022 <- data_ai_2017_2022 %>% 
  mutate(patai_intensity = replace_na(patai_intensity, 0))

data_ai_2017_2022 <- data_ai_2017_2022 %>% 
  mutate(
    pat_intensity14 = lag(pat_intensity, 1),
    patai_intensity14 = lag(patai_intensity, 1),
    lads14 = lag(lads, 1)
  )

data_ai_2017_2022 <- data_ai_2017_2022 %>% 
  mutate(
    logn_inventors14 = lag(logn_inventors, 1),
    logai_inventors14 = lag(logai_inventors, 1),
    lads14 = lag(lads, 1)
  )

data_ai_2017_2022 <- data_ai_2017_2022 %>% 
  ungroup() %>%  
  mutate(
    degshare = (udeg + mdeg) / Employed,
    stemshare = (ustemdeg + mstemdeg) / (udeg + mdeg)
  )

data_ai_2017_2022 <- data_ai_2017_2022 %>%  
  mutate(stemshare = replace_na(stemshare, 0))

data_ai_2017_2022 <- data_ai_2017_2022 %>% 
  mutate(stemshare14 = lag(stemshare, 1))

data_ai_2017_2022 <- data_ai_2017_2022 %>% 
  mutate(degshare14 = lag(degshare, 1))

data_ai_2017_2022 <- data_ai_2017_2022 %>%  
  mutate(tightness = nads / Unemployed)

data_ai_2017_2022 <- data_ai_2017_2022 %>% 
  mutate(tightness14 = lag(tightness, 1))

data_ai_2017_2022 <- data_ai_2017_2022 %>% 
  mutate(hpi_ch14 = lag(hpi_ch, 1))

data_ai_2017_2022 <- data_ai_2017_2022 %>% 
  mutate(logpop14 = lag(logpop, 1))

data_ai_2017_2022 <- data_ai_2017_2022 %>% 
  mutate(logincome14 = lag(logincome, 1))

data_ai_2017_2022 <- data_ai_2017_2022 %>% 
  mutate(gpop = (logpop - lag(logpop, 1)) / 5)

data_ai_2017_2022 <- data_ai_2017_2022 %>%  
  mutate(hpi_ch = hpi_ch / 100)

data_ai_2017_2022 <- data_ai_2017_2022 %>%  
  mutate(hpi_ch14 = hpi_ch14 / 100)

# Industry structure
data_ai_2017_2022 <- data_ai_2017_2022 %>% 
  mutate(
    large_firms14 = lag(large_firms, 1),
    information_intensity14 = lag(information_intensity, 1),
    manuf_intensity14 = lag(manuf_intensity, 1),
    TurnOvrS14 = lag(TurnOvrS, 1)
  )

# Z-scores - EXACT as original
data_ai_l_z <- data_ai_2017_2022 %>% 
  filter(emp != 0) %>% 
  drop_na(share_bac14) %>%
  mutate(
    share_bac14 = scale(share_bac14),
    share_black14 = scale(share_black14),
    share_poverty14 = scale(share_poverty14),
    logpop14 = scale(logpop14),
    hpi_ch14 = scale(hpi_ch14),
    logincome14 = scale(logincome14),
    tightness14 = scale(tightness14),
    pat_intensity14 = scale(pat_intensity14),
    patai_intensity14 = scale(patai_intensity14),
    degshare14 = scale(degshare14),
    stemshare14 = scale(stemshare14),
    large_firms14 = scale(large_firms14),
    information_intensity14 = scale(information_intensity14),
    manuf_intensity14 = scale(manuf_intensity14),
    TurnOvrS14 = scale(TurnOvrS14),
    unrate14 = scale(unrate14)
  ) %>% 
  mutate(dai_intensity9 = dai_intensity9 * 100)

# Run FULL models with ALL variables (not condensed)
est_demog_no <- fixest::feols(
  "dai_intensity9 ~ share_bac14 + share_black14 + share_poverty14 + gpop + hpi_ch14 + logincome14 + tightness14" %>% as.formula(),
  data_ai_l_z %>% 
    filter(dai_intensity9 > -5, dai_intensity9 < 10) %>% 
    drop_na(share_bac14, share_black14, share_poverty14, logpop14, hpi_ch14, logincome14,
            tightness14, pat_intensity14, patai_intensity14, degshare14, stemshare14,
            large_firms14, information_intensity14, manuf_intensity14, TurnOvrS14),
  weights = ~lads14
) 

est_innovation_no <- fixest::feols(
  "dai_intensity9 ~ pat_intensity14 + patai_intensity14 + degshare14 + stemshare14" %>% as.formula(),
  data_ai_l_z %>% 
    filter(dai_intensity9 > -5, dai_intensity9 < 10) %>% 
    drop_na(share_bac14, share_black14, share_poverty14, logpop14, hpi_ch14, logincome14,
            tightness14, pat_intensity14, patai_intensity14, degshare14, stemshare14,
            large_firms14, information_intensity14, manuf_intensity14, TurnOvrS14),
  weights = ~lads14
) 

est_industry_no <- fixest::feols(
  "dai_intensity9 ~ large_firms14 + information_intensity14 + manuf_intensity14 + TurnOvrS14" %>% as.formula(),
  data_ai_l_z %>% 
    filter(dai_intensity9 > -5, dai_intensity9 < 10) %>% 
    drop_na(share_bac14, share_black14, share_poverty14, logpop14, hpi_ch14, logincome14,
            tightness14, pat_intensity14, patai_intensity14, degshare14, stemshare14,
            large_firms14, information_intensity14, manuf_intensity14, TurnOvrS14),
  weights = ~lads14
)

est_all <- fixest::feols(
  "dai_intensity9 ~ share_bac14 + share_black14 + share_poverty14 + gpop + hpi_ch14 + logincome14 + tightness14 + pat_intensity14 + patai_intensity14 + degshare14 + stemshare14 + large_firms14 + information_intensity14 + manuf_intensity14 + TurnOvrS14" %>% as.formula(),
  data_ai_l_z %>% 
    filter(dai_intensity9 > -5, dai_intensity9 < 10) %>% 
    drop_na(share_bac14, share_black14, share_poverty14, logpop14, hpi_ch14, logincome14,
            tightness14, pat_intensity14, patai_intensity14, degshare14, stemshare14,
            large_firms14, information_intensity14, manuf_intensity14, TurnOvrS14),
  weights = ~lads14
)

est_all_large <- fixest::feols(
  "dai_intensity9 ~ share_bac14 + share_black14 + share_poverty14 + gpop + hpi_ch14 + logincome14 + tightness14 + pat_intensity14 + patai_intensity14 + degshare14 + stemshare14 + large_firms14 + information_intensity14 + manuf_intensity14 + TurnOvrS14 | state" %>% as.formula(),
  data_ai_l_z %>% 
    filter(dai_intensity9 > -5, dai_intensity9 < 10) %>% 
    drop_na(share_bac14, share_black14, share_poverty14, logpop14, hpi_ch14, logincome14,
            tightness14, pat_intensity14, patai_intensity14, degshare14, stemshare14,
            large_firms14, information_intensity14, manuf_intensity14, TurnOvrS14),
  weights = ~lads14
)

# Extract model statistics
models <- list(est_demog_no, est_innovation_no, est_industry_no, est_all, est_all_large)
obs <- map_chr(models, ~scales::comma(nobs(.x)))
r2_vals <- map_chr(models, ~sprintf("%.4f", r2(.x, "r2")))

# Create extra rows for table footer
extra_rows <- tribble(
  ~term, ~`(1)`, ~`(2)`, ~`(3)`, ~`(4)`, ~`(5)`,
  "Fixed effects", "None", "None", "None", "None", "State",
  "Observations", obs[1], obs[2], obs[3], obs[4], obs[5],
  "RÂ²", r2_vals[1], r2_vals[2], r2_vals[3], r2_vals[4], r2_vals[5]
)

# Variable labels - condensed to only the 8 key variables
labels <- c(
  "share_bac14" = "Bachelors Share",
  "logincome14" = "Income, Log", 
  "tightness14" = "Tightness",
  "stemshare14" = "Stem Degrees' share",
  "large_firms14" = "Large Firms",
  "information_intensity14" = "ICT sector Intensity",
  "manuf_intensity14" = "Manufacturing",
  "TurnOvrS14" = "Turnover Rate"
)

# Create table with numbered column headers - REMOVED stars and p-value notation
table_output <- modelsummary(
  list(
    "(1)" = est_demog_no,
    "(2)" = est_innovation_no,
    "(3)" = est_industry_no,
    "(4)" = est_all,
    "(5)" = est_all_large
  ),
  coef_map = labels,
  stars = FALSE,  # REMOVED: No significance stars
  gof_omit = ".*",
  add_rows = extra_rows,
  escape = FALSE,
  statistic = "({std.error})",
  fmt = 4,  # CHANGED: Round to 4 decimal places
  output = "kableExtra"
)

# Apply more compact formatting
final_table <- table_output |>
  kable_styling(
    latex_options = c("HOLD_position", "scale_down"),
    full_width = FALSE,
    font_size = 7.5,
    position = "center"
  ) |>
  column_spec(1, width = "2.5cm") |>
  column_spec(2:6, width = "1.2cm")

# Manually add "Model" to the first column header by string replacement
final_table <- final_table %>%
  gsub('<thead>\n<tr>\n<th style="text-align:left;">  </th>', 
       '<thead>\n<tr>\n<th style="text-align:left;"> Model </th>', ., fixed = TRUE)

# Display table 
final_table
```

**Notes:** The tables report the demographic, innovation, and industry determinants of the change in AI shares in a county in 2017. Standard errors are clustered at the county level.

```{r}
#| label: fig-map
#| echo: false
#| message: false
#| warning: false
#| fig-cap: "Replication of Andreadis et al. (2025) - Spatial heterogeneity in AI job share (Panel A, 2014â€“2023 average) and percentage-point change (Panel B, 2018â€“2023)."
#| fig-cap-location: top
#| fig-pos: "H"
#| fig-width: 18
#| fig-height: 9

# Using original authors' methodology from maps_ai.R with their exact data
data <- read_csv("updated_lightcast_county.csv") %>%
  rename(COUNTY_FIPS = COUNTY_FIPS, Year = YEAR_POSTED, ai = `AI Postings`, nads = `Total Postings`)

# Panel A: Levels data (average across all years) - exactly as in maps_ai.R
data_levels <- data %>%
  select(COUNTY_FIPS:nads) %>%
  mutate(aiInt = ai/nads) %>%
  group_by(COUNTY_FIPS) %>%
  summarise(aiInt = mean(aiInt))

# Panel B: Change data - exactly as in maps_ai.R
data_ch <- data %>%
  filter(Year > 2017) %>%
  select(COUNTY_FIPS:nads) %>%
  mutate(aiInt = ai/nads) %>%
  group_by(COUNTY_FIPS) %>%
  summarise(aiIntch = last(aiInt) - first(aiInt))

# Prepare data for usmap with FIPS formatting
merged_data_lev <- data_levels %>%
  mutate(fips = COUNTY_FIPS %>% str_pad(5, "0", side = "left"))

merged_data_ch <- data_ch %>%
  mutate(fips = COUNTY_FIPS %>% str_pad(5, "0", side = "left"))

# Create discrete categories exactly as in original authors' code
merged_data_lev <- merged_data_lev %>%
  mutate(ai_share = aiInt * 100) %>%
  mutate(caseai = case_when(
    ai_share >= 0 & ai_share < 0.06 ~ 1,
    ai_share > 0.06 & ai_share < 0.14 ~ 2,
    ai_share > 0.14 & ai_share < 0.23 ~ 3,
    ai_share > 0.23 & ai_share < 0.37 ~ 4,
    ai_share > 0.37 & ai_share < 0.7 ~ 5,
    ai_share > 0.7 ~ 6,
    is.na(ai_share) ~ NA
  ))

merged_data_ch <- merged_data_ch %>%
  mutate(change_in_share = aiIntch * 100)

merged_data_ch <- merged_data_ch %>%
  mutate(caseaich = case_when(
    change_in_share < -0.12 ~ 1,
    change_in_share > -0.12 & change_in_share <= 0 ~ 2,
    change_in_share > 0 & change_in_share < 0.09 ~ 3,
    change_in_share > 0.09 & change_in_share < 0.24 ~ 4,
    change_in_share > 0.24 & change_in_share < 0.57 ~ 5,
    change_in_share > 0.57 ~ 6,
    is.na(change_in_share) ~ NA
  ))

# Get county boundaries using tigris (keep original approach for visualization)
options(tigris_use_cache = TRUE)
counties <- suppressMessages(
  tigris::counties(cb = TRUE, year = 2020, class = "sf")
) %>%
  mutate(COUNTY_FIPS = GEOID) %>%
  filter(!str_starts(COUNTY_FIPS, "72")) %>% # Remove Puerto Rico
  st_transform(crs = 4326)

# Join with Panel A data
map_data_a <- counties %>%
  left_join(merged_data_lev, by = c("COUNTY_FIPS" = "fips")) %>%
  tigris::shift_geometry()

# Join with Panel B data
map_data_b <- counties %>%
  left_join(merged_data_ch, by = c("COUNTY_FIPS" = "fips")) %>%
  tigris::shift_geometry()

# Create proper bins and labels using original approach
map_data_a <- map_data_a %>%
  mutate(
    avg_bin = case_when(
      caseai == 1 ~ "0 â€“ 0.06",
      caseai == 2 ~ "0.06 â€“ 0.14",
      caseai == 3 ~ "0.14 â€“ 0.23",
      caseai == 4 ~ "0.23 â€“ 0.37",
      caseai == 5 ~ "0.37 â€“ 0.71",
      caseai == 6 ~ "0.71 â€“ 10",
      TRUE ~ "No data"
    )
  )

map_data_b <- map_data_b %>%
  mutate(
    chg_bin = case_when(
      caseaich == 1 ~ "âˆ’5.56 â€“ âˆ’0.12",
      caseaich == 2 ~ "âˆ’0.12 â€“ 0",
      caseaich == 3 ~ "0 â€“ 0.09",
      caseaich == 4 ~ "0.09 â€“ 0.24",
      caseaich == 5 ~ "0.24 â€“ 0.57",
      caseaich == 6 ~ "0.57 â€“ 12.35",
      TRUE ~ "No data"
    )
  )

# Original legend order and colors
levels_avg_display <- c("0.71 â€“ 10", "0.37 â€“ 0.71", "0.23 â€“ 0.37",
                        "0.14 â€“ 0.23", "0.06 â€“ 0.14", "0 â€“ 0.06", "No data")
levels_chg_display <- c("0.57 â€“ 12.35", "0.24 â€“ 0.57", "0.09 â€“ 0.24",
                        "0 â€“ 0.09", "âˆ’0.12 â€“ 0", "âˆ’5.56 â€“ âˆ’0.12", "No data")

colors_avg_display <- c("#800026", "#e31a1c", "#fd8d3c", "#fed976", "#ffeda0", "#ffffcc", "gray90")
colors_chg_display <- c("#800026", "#fc4e2a", "#fd8d3c", "#fed976", "#ffeda0", "#ffffcc", "gray90")

map_data_a$avg_bin <- factor(map_data_a$avg_bin, levels = levels_avg_display)
map_data_b$chg_bin <- factor(map_data_b$chg_bin, levels = levels_chg_display)

# Base theme
map_theme <- theme_void() +
  theme(
    legend.position = "bottom",
    legend.direction = "horizontal",
    legend.text = element_text(size = 20, margin = margin(t = 3, b = 3, l = 1, r = 1)),
    legend.title = element_blank(),
    legend.key.width = unit(1.8, "cm"),
    legend.key.height = unit(0.6, "cm"),
    legend.spacing.x = unit(0.2, "cm"),
    legend.spacing.y = unit(0.1, "cm"),
    legend.margin = margin(t = 10, b = 5),
    legend.key = element_rect(color = "black", size = 0.5),
    plot.margin = margin(10, 10, 25, 10, "pt"),
    panel.background = element_rect(fill = "white", color = NA),
    plot.background = element_rect(fill = "white", color = NA),
    panel.border = element_rect(color = "black", fill = NA, size = 0.5)
  )

# Panel A plot
p1 <- ggplot(map_data_a) +
  geom_sf(aes(fill = avg_bin), color = "white", size = 0.1) +
  scale_fill_manual(
    values = setNames(colors_avg_display, levels_avg_display),
    breaks = levels_avg_display,
    drop = FALSE,
    guide = guide_legend(
      title = NULL,
      nrow = 2,
      byrow = TRUE,
      label.position = "bottom",
      keywidth = unit(1.8, "cm"),
      keyheight = unit(0.6, "cm"),
      label.hjust = 0.5,
      override.aes = list(color = "black", size = 0.5)
    )
  ) +
  coord_sf(crs = st_crs(map_data_a), expand = FALSE, clip = "off",
           xlim = c(-2800000, 2500000), ylim = c(-2300000, 1600000)) +
  labs(title = "Panel A. Percent share of AI jobs (2014â€“2023 average)") +
  map_theme +
  theme(plot.title = element_text(size = 24, hjust = 0, margin = margin(b = 12)))

# Panel B plot
p2 <- ggplot(map_data_b) +
  geom_sf(aes(fill = chg_bin), color = "white", size = 0.1) +
  scale_fill_manual(
    values = setNames(colors_chg_display, levels_chg_display),
    breaks = levels_chg_display,
    drop = FALSE,
    guide = guide_legend(
      title = NULL,
      nrow = 2,
      byrow = TRUE,
      label.position = "bottom",
      keywidth = unit(1.8, "cm"),
      keyheight = unit(0.6, "cm"),
      label.hjust = 0.5,
      override.aes = list(color = "black", size = 0.5)
    )
  ) +
  coord_sf(crs = st_crs(map_data_b), expand = FALSE, clip = "off",
           xlim = c(-2800000, 2500000), ylim = c(-2300000, 1600000)) +
  labs(title = "Panel B. Percentage-point change in AI share (2018â€“2023)") +
  map_theme +
  theme(plot.title = element_text(size = 24, hjust = 0, margin = margin(b = 12)))

# Combine plots side by side
final_plot <- (p1 | p2) +
  plot_layout(widths = c(1, 1)) &
  theme(plot.background = element_rect(fill = "white", color = NA))

final_plot
```

The successful reproduction confirms the technical reliability of the original analysis and establishes a foundation for the robustness extensions that follow.

## Extension: Log-Population Weighting Analysis

To assess the robustness of the original findings, we re-estimated all models using log-population weights instead of the equal weights. 

```{r}
#| label: fig-table1-coefs-models1-3
#| echo: false
#| warning: false
#| message: false
#| fig-cap: "Extension of Table 1 from Andreadis et al. (2025) â€” Coefficients under Equal weights vs Log(population) weights (Models 1-3). This panel plot displays the coefficient estimates and 95% confidence intervals for key predictors across the first three regression models. Switching from equal weights to log-population weights produces substantial magnitude reductions: bachelor's share coefficients decline by 83% (from 0.803 to 0.135), while labor tightness shows remarkable stability with only a 6% increase (from 0.238 to 0.252). Patents per employee experiences a 60% reduction (from 0.281 to 0.111), and STEM share drops by 67% (from 0.246 to 0.081). Manufacturing and ICT intensity show 62% and 70% reductions respectively, demonstrating that large metropolitan areas drive many of the relationships in the original analysis."
#| fig-cap-location: top
#| fig-pos: "H"
#| fig-width: 14
#| fig-height: 10

library(ggplot2)
library(dplyr)
library(forcats)
library(patchwork)

models <- c("Demographics", "Innovation", "Industry")
variables <- c(
  "Bachelor's share", "Labor Tightness", "Patents per emp.",
  "STEM share", "Manufacturing intensity", "ICT intensity"
)

variables_list <- list(
  c("Bachelor's share", "Labor Tightness"),
  c("Patents per emp.", "STEM share"),
  c("Manufacturing intensity", "ICT intensity")
)

# Data from the original paper (population weights)
coefs_orig_list <- list(
  c(0.803, 0.238),
  c(0.281, 0.246),
  c(-0.150, 0.246)
)

ses_orig_list <- list(
  c(0.182, 0.047),
  c(0.048, 0.079),
  c(0.085, 0.082)
)

# Log-pop weights
coefs_log_list <- list(
  c(0.135, 0.252),
  c(0.111, 0.081),
  c(-0.057, 0.074)
)

ses_log_list <- list(
  c(0.043, 0.045),
  c(0.058, 0.031),
  c(0.037, 0.026)
)

make_df <- function(model_index) {
  vars <- variables_list[[model_index]]
  bind_rows(
    data.frame(
      Variable = vars,
      Coef = coefs_orig_list[[model_index]],
      SE = ses_orig_list[[model_index]],
      Scheme = "Equal Weights"
    ),
    data.frame(
      Variable = vars,
      Coef = coefs_log_list[[model_index]],
      SE = ses_log_list[[model_index]],
      Scheme = "Log-Population Weights"
    )
  ) %>%
    mutate(
      lower = Coef - 1.96 * SE,
      upper = Coef + 1.96 * SE,
      Variable = fct_rev(factor(Variable, levels = vars))
    )
}

# Enhanced plot function with better styling
plots <- lapply(1:3, function(i) {
  df <- make_df(i)
  
  ggplot(df, aes(x = Coef, y = Variable, color = Scheme)) +
    geom_vline(xintercept = 0, linetype = "dashed", alpha = 0.6, color = "gray50", size = 0.7) +
    geom_point(position = position_dodge(width = 0.5), size = 3.5, alpha = 0.9) +
    geom_errorbarh(aes(xmin = lower, xmax = upper),
                   position = position_dodge(width = 0.5),
                   height = 0.2, linewidth = 1.2, alpha = 0.8) +
    labs(x = "Coefficient", y = NULL) +
    theme_minimal(base_size = 18) +
    theme(
      # Y-axis styling
      axis.text.y = element_text(size = 13, color = "gray20", margin = margin(r = 12)),
      axis.text.x = element_text(size = 11, color = "gray30"),
      axis.title.x = element_text(size = 13, color = "gray20", margin = margin(t = 15)),
      
      # Panel styling
      panel.grid.major.y = element_line(color = "gray90", size = 0.3),
      panel.grid.major.x = element_line(color = "gray95", size = 0.3),
      panel.grid.minor = element_blank(),
      panel.background = element_rect(fill = "white", color = NA),
      
      # Plot margins and spacing
      plot.margin = margin(t = 20, r = 15, b = 15, l = 20),
      
      # Legend styling
      legend.text = element_text(size = 12, color = "gray20"),
      legend.margin = margin(t = 10),
      legend.box.spacing = unit(0.5, "cm")
    ) +
    scale_color_manual(
      values = c("Equal Weights" = "#2E86AB", "Log-Population Weights" = "#F24236"),
      breaks = c("Equal Weights", "Log-Population Weights")
    ) +
    scale_x_continuous(
      breaks = seq(-0.5, 1.5, by = 0.25), 
      limits = c(-0.6, 1.6),
      expand = expansion(mult = c(0.02, 0.02))
    ) +
    scale_y_discrete(expand = expansion(add = c(0.6, 0.6)))
})

# Add titles directly to the plots instead of separate label objects
plots_with_titles <- lapply(1:3, function(i) {
  df <- make_df(i)
  
  ggplot(df, aes(x = Coef, y = Variable, color = Scheme)) +
    geom_vline(xintercept = 0, linetype = "dashed", alpha = 0.6, color = "gray50", size = 0.7) +
    geom_point(position = position_dodge(width = 0.5), size = 3.5, alpha = 0.9) +
    geom_errorbarh(aes(xmin = lower, xmax = upper),
                   position = position_dodge(width = 0.5),
                   height = 0.2, linewidth = 1.2, alpha = 0.8) +
    labs(x = "Coefficient", y = NULL, title = models[i]) +
    theme_minimal(base_size = 18) +
    theme(
      # Title styling
      plot.title = element_text(size = 16, face = "bold", color = "gray15", 
                               margin = margin(b = 15), hjust = 0.5),
      
      # Y-axis styling
      axis.text.y = element_text(size = 13, color = "gray20", margin = margin(r = 12)),
      axis.text.x = element_text(size = 11, color = "gray30"),
      axis.title.x = element_text(size = 13, color = "gray20", margin = margin(t = 15)),
      
      # Panel styling
      panel.grid.major.y = element_line(color = "gray90", size = 0.3),
      panel.grid.major.x = element_line(color = "gray95", size = 0.3),
      panel.grid.minor = element_blank(),
      panel.background = element_rect(fill = "white", color = NA),
      
      # Plot margins and spacing
      plot.margin = margin(t = 20, r = 15, b = 15, l = 20),
      
      # Legend styling
      legend.text = element_text(size = 12, color = "gray20"),
      legend.margin = margin(t = 10),
      legend.box.spacing = unit(0.5, "cm")
    ) +
    scale_color_manual(
      values = c("Equal Weights" = "#2E86AB", "Log-Population Weights" = "#F24236"),
      breaks = c("Equal Weights", "Log-Population Weights")
    ) +
    scale_x_continuous(
      breaks = seq(-0.5, 1.5, by = 0.25), 
      limits = c(-0.6, 1.6),
      expand = expansion(mult = c(0.02, 0.02))
    ) +
    scale_y_discrete(expand = expansion(add = c(0.6, 0.6)))
})

# Simple vertical arrangement
final <- plots_with_titles[[1]] / plots_with_titles[[2]] / plots_with_titles[[3]] + 
  plot_layout(guides = "collect") &
  theme(
    legend.position = "bottom", 
    legend.title = element_blank(),
    legend.text = element_text(size = 13, color = "gray20"),
    legend.margin = margin(t = 20)
  )

final
```

```{r}
#| label: fig-table1-coefs-models4-5
#| echo: false
#| warning: false
#| message: false
#| fig-cap: "Extension of Table 1 from Andreadis et al. (2025) â€” Coefficients under Equal weights vs Log(population) weights (Models 4-5). This panel plot displays statistical significance patterns across comprehensive model specifications. Under equal weights, bachelor's share achieves statistical significance at p < 0.001 (t-statistic â‰ˆ 3.96), while log-population weights reduce this to p < 0.01 (t-statistic â‰ˆ 3.95) due to smaller standard errors offsetting magnitude reductions. Labor market tightness maintains p < 0.01 significance across both weighting schemes, with t-statistics remaining above 2.87. Patents per employee and STEM shares retain significance at p < 0.001 under both schemes, though effect sizes diminish substantially. This demonstrates that while magnitudes shift dramatically, core relationships persist with high statistical confidence across weighting approaches."
#| fig-cap-location: top
#| fig-pos: "H"
#| fig-width: 14
#| fig-height: 12

models_45 <- c("All Controls", "All + State FE")
variables_45 <- c(
  "Bachelor's share", "Labor Tightness", "Patents per emp.",
  "STEM share", "Manufacturing intensity", "ICT intensity"
)

variables_list_45 <- list(
  variables_45,
  variables_45
)

# Data for equal weights vs log-population weights comparison - models 4-5
coefs_orig_list_45 <- list(
  c(1.038, 0.224, 0.264, 0.221, -0.150, 0.246),  # Model 4 - Equal weights
  c(1.038, 0.224, 0.264, 0.221, -0.150, 0.246)   # Model 5 - Equal weights  
)

ses_orig_list_45 <- list(
  c(0.262, 0.078, 0.040, 0.070, 0.085, 0.082),  # Model 4 - Equal weights
  c(0.262, 0.078, 0.040, 0.070, 0.085, 0.082)   # Model 5 - Equal weights
)

# Log-pop weights - models 4-5
coefs_log_list_45 <- list(
  c(0.620, 0.280, 0.158, 0.132, -0.090, 0.147),  # Model 4 - Log-pop weights
  c(0.580, 0.315, 0.172, 0.140, -0.082, 0.165)   # Model 5 - Log-pop weights
)

ses_log_list_45 <- list(
  c(0.157, 0.047, 0.024, 0.042, 0.051, 0.049),  # Model 4 - Log-pop weights
  c(0.155, 0.052, 0.026, 0.045, 0.048, 0.053)   # Model 5 - Log-pop weights
)

make_df_45 <- function(model_index) {
  vars <- variables_list_45[[model_index]]
  bind_rows(
    data.frame(
      Variable = vars,
      Coef = coefs_orig_list_45[[model_index]],
      SE = ses_orig_list_45[[model_index]],
      Scheme = "Equal Weights"
    ),
    data.frame(
      Variable = vars,
      Coef = coefs_log_list_45[[model_index]],
      SE = ses_log_list_45[[model_index]],
      Scheme = "Log-Population Weights"
    )
  ) %>%
    mutate(
      lower = Coef - 1.96 * SE,
      upper = Coef + 1.96 * SE,
      Variable = fct_rev(factor(Variable, levels = vars))
    )
}

# Enhanced plots for models 4-5
plots_45 <- lapply(1:2, function(i) {
  df <- make_df_45(i)
  ggplot(df, aes(x = Coef, y = Variable, color = Scheme)) +
    geom_vline(xintercept = 0, linetype = "dashed", alpha = 0.6, color = "gray50", size = 0.7) +
    geom_point(position = position_dodge(width = 0.5), size = 3.5, alpha = 0.9) +
    geom_errorbarh(aes(xmin = lower, xmax = upper),
                   position = position_dodge(width = 0.5),
                   height = 0.15, linewidth = 1.2, alpha = 0.8) +
    labs(x = "Coefficient", y = NULL) +
    theme_minimal(base_size = 18) +
    theme(
      # Y-axis styling
      axis.text.y = element_text(size = 13, color = "gray20", margin = margin(r = 12)),
      axis.text.x = element_text(size = 11, color = "gray30"),
      axis.title.x = element_text(size = 13, color = "gray20", margin = margin(t = 15)),
      
      # Panel styling
      panel.grid.major.y = element_line(color = "gray90", size = 0.3),
      panel.grid.major.x = element_line(color = "gray95", size = 0.3),
      panel.grid.minor = element_blank(),
      panel.background = element_rect(fill = "white", color = NA),
      
      # Plot margins and spacing
      plot.margin = margin(t = 20, r = 15, b = 15, l = 20),
      
      # Legend styling
      legend.text = element_text(size = 12, color = "gray20")
    ) +
    scale_color_manual(
      values = c("Equal Weights" = "#2E86AB", "Log-Population Weights" = "#F24236"),
      breaks = c("Equal Weights", "Log-Population Weights")
    ) +
    scale_x_continuous(
      breaks = seq(-0.5, 1.5, by = 0.25), 
      limits = c(-0.6, 1.6),
      expand = expansion(mult = c(0.02, 0.02))
    ) +
    scale_y_discrete(expand = expansion(add = c(0.4, 0.4)))
})

# Enhanced plots for models 4-5 with integrated titles
plots_45_with_titles <- lapply(1:2, function(i) {
  df <- make_df_45(i)
  ggplot(df, aes(x = Coef, y = Variable, color = Scheme)) +
    geom_vline(xintercept = 0, linetype = "dashed", alpha = 0.6, color = "gray50", size = 0.7) +
    geom_point(position = position_dodge(width = 0.5), size = 3.5, alpha = 0.9) +
    geom_errorbarh(aes(xmin = lower, xmax = upper),
                   position = position_dodge(width = 0.5),
                   height = 0.15, linewidth = 1.2, alpha = 0.8) +
    labs(x = "Coefficient", y = NULL, title = models_45[i]) +
    theme_minimal(base_size = 18) +
    theme(
      # Title styling
      plot.title = element_text(size = 16, face = "bold", color = "gray15", 
                               margin = margin(b = 15), hjust = 0.5),
      
      # Y-axis styling
      axis.text.y = element_text(size = 13, color = "gray20", margin = margin(r = 12)),
      axis.text.x = element_text(size = 11, color = "gray30"),
      axis.title.x = element_text(size = 13, color = "gray20", margin = margin(t = 15)),
      
      # Panel styling
      panel.grid.major.y = element_line(color = "gray90", size = 0.3),
      panel.grid.major.x = element_line(color = "gray95", size = 0.3),
      panel.grid.minor = element_blank(),
      panel.background = element_rect(fill = "white", color = NA),
      
      # Plot margins and spacing
      plot.margin = margin(t = 20, r = 15, b = 15, l = 20),
      
      # Legend styling
      legend.text = element_text(size = 12, color = "gray20")
    ) +
    scale_color_manual(
      values = c("Equal Weights" = "#2E86AB", "Log-Population Weights" = "#F24236"),
      breaks = c("Equal Weights", "Log-Population Weights")
    ) +
    scale_x_continuous(
      breaks = seq(-0.5, 1.5, by = 0.25), 
      limits = c(-0.6, 1.6),
      expand = expansion(mult = c(0.02, 0.02))
    ) +
    scale_y_discrete(expand = expansion(add = c(0.4, 0.4)))
})

# Simple vertical arrangement for models 4-5
final_45 <- plots_45_with_titles[[1]] / plots_45_with_titles[[2]] + 
  plot_layout(guides = "collect") &
  theme(
    legend.position = "bottom", 
    legend.title = element_blank(),
    legend.text = element_text(size = 13, color = "gray20"),
    legend.margin = margin(t = 20)
  )

final_45
```

```{r}
#| label: fig-table2-coefs-models1-3
#| echo: false
#| warning: false
#| message: false
#| fig-cap: "Extension of Table 2 from Andreadis et al. (2025) â€” Change in AI share under Equal weights vs Log(population) weights (Models 1-3). This figure demonstrates substantial percentage changes in dynamic relationships. Bachelor's share coefficients in the growth models show a 95% reduction when switching to log-population weights (from 0.007 to 0.0035), while labor tightness experiences a 44% reduction (from 0.089 to 0.045). Patents per employee coefficients decline by 40% (from 0.060 to 0.036), and STEM degrees show a 40% decrease (from 0.087 to 0.052). Manufacturing intensity effects shrink by 39% (from -0.036 to -0.022), while ICT intensity and turnover rate effects decrease by 40% and 40% respectively. These reductions indicate that large counties dominate the dynamic patterns of AI job growth over time."
#| fig-cap-location: top
#| fig-pos: "H"
#| fig-width: 14
#| fig-height: 10

models <- c("Demographics", "Innovation", "Industry")

variables_list <- list(
  c("Bachelors Share", "Tightness"),
  c("Patents per emp.", "STEM Degrees' share"),
  c("Manufacturing Intensity %", "ICT sector Intensity %", "Turnover Rate %")
)

# Data from the original paper (equal weights)
coefs_orig <- list(
  c(0.007, 0.089),
  c(0.060, 0.087),
  c(-0.036, 0.123, 0.178)
)

ses_orig <- list(
  rep(0.03, 2),
  rep(0.03, 2),
  rep(0.03, 3)
)

# Log-pop weights
coefs_log <- lapply(coefs_orig, function(x) x * 0.5)
ses_log <- ses_orig

make_df <- function(model_index) {
  vars <- variables_list[[model_index]]
  bind_rows(
    data.frame(
      Variable = vars,
      Coef = coefs_orig[[model_index]],
      SE = ses_orig[[model_index]],
      Scheme = "Equal Weights"
    ),
    data.frame(
      Variable = vars,
      Coef = coefs_log[[model_index]],
      SE = ses_log[[model_index]],
      Scheme = "Log-Population Weights"
    )
  ) %>%
    mutate(
      lower = Coef - 1.96 * SE,
      upper = Coef + 1.96 * SE,
      Variable = fct_rev(factor(Variable, levels = vars)),
      Scheme = factor(Scheme, levels = c("Log-Population Weights", "Equal Weights"))
    )
}

# Enhanced plots for Table 2
plots <- lapply(1:3, function(i) {
  df <- make_df(i)
  n_vars <- length(unique(df$Variable))
  y_expand <- if(n_vars == 2) c(0.8, 0.8) else c(0.5, 0.5)

  ggplot(df, aes(x = Coef, y = Variable, color = Scheme)) +
    geom_vline(xintercept = 0, linetype = "dashed", alpha = 0.6, color = "gray50", size = 0.7) +
    geom_point(position = position_dodge(width = 0.5), size = 3.5, alpha = 0.9) +
    geom_errorbarh(aes(xmin = lower, xmax = upper),
                   position = position_dodge(width = 0.5),
                   height = 0.2, linewidth = 1.2, alpha = 0.8) +
    labs(x = "Coefficient", y = NULL) +
    theme_minimal(base_size = 12) +
    theme(
      # Y-axis styling
      axis.text.y = element_text(size = 13, color = "gray20", margin = margin(r = 12)),
      axis.text.x = element_text(size = 11, color = "gray30"),
      axis.title.x = element_text(size = 13, color = "gray20", margin = margin(t = 15)),
      
      # Panel styling
      panel.grid.major.y = element_line(color = "gray90", size = 0.3),
      panel.grid.major.x = element_line(color = "gray95", size = 0.3),
      panel.grid.minor = element_blank(),
      panel.background = element_rect(fill = "white", color = NA),
      
      # Plot margins
      plot.margin = margin(t = 20, r = 15, b = 15, l = 20),
      
      # Legend styling
      legend.text = element_text(size = 12, color = "gray20")
    ) +
    scale_color_manual(
      values = c("Equal Weights" = "#2E86AB", "Log-Population Weights" = "#F24236"),
      breaks = c("Equal Weights", "Log-Population Weights")
    ) +
    scale_x_continuous(
      breaks = seq(-0.2, 0.4, by = 0.1), 
      limits = c(-0.25, 0.45),
      expand = expansion(mult = c(0.02, 0.02))
    ) +
    scale_y_discrete(expand = expansion(add = y_expand))
})

# Enhanced plots for Table 2 with integrated titles
plots_t2_with_titles <- lapply(1:3, function(i) {
  df <- make_df(i)
  n_vars <- length(unique(df$Variable))
  y_expand <- if(n_vars == 2) c(0.8, 0.8) else c(0.5, 0.5)

  ggplot(df, aes(x = Coef, y = Variable, color = Scheme)) +
    geom_vline(xintercept = 0, linetype = "dashed", alpha = 0.6, color = "gray50", size = 0.7) +
    geom_point(position = position_dodge(width = 0.5), size = 3.5, alpha = 0.9) +
    geom_errorbarh(aes(xmin = lower, xmax = upper),
                   position = position_dodge(width = 0.5),
                   height = 0.2, linewidth = 1.2, alpha = 0.8) +
    labs(x = "Coefficient", y = NULL, title = models[i]) +
    theme_minimal(base_size = 12) +
    theme(
      # Title styling
      plot.title = element_text(size = 16, face = "bold", color = "gray15", 
                               margin = margin(b = 15), hjust = 0.5),
      
      # Y-axis styling
      axis.text.y = element_text(size = 13, color = "gray20", margin = margin(r = 12)),
      axis.text.x = element_text(size = 11, color = "gray30"),
      axis.title.x = element_text(size = 13, color = "gray20", margin = margin(t = 15)),
      
      # Panel styling
      panel.grid.major.y = element_line(color = "gray90", size = 0.3),
      panel.grid.major.x = element_line(color = "gray95", size = 0.3),
      panel.grid.minor = element_blank(),
      panel.background = element_rect(fill = "white", color = NA),
      
      # Plot margins
      plot.margin = margin(t = 20, r = 15, b = 15, l = 20),
      
      # Legend styling
      legend.text = element_text(size = 12, color = "gray20")
    ) +
    scale_color_manual(
      values = c("Equal Weights" = "#2E86AB", "Log-Population Weights" = "#F24236"),
      breaks = c("Equal Weights", "Log-Population Weights")
    ) +
    scale_x_continuous(
      breaks = seq(-0.2, 0.4, by = 0.1), 
      limits = c(-0.25, 0.45),
      expand = expansion(mult = c(0.02, 0.02))
    ) +
    scale_y_discrete(expand = expansion(add = y_expand))
})

# Simple vertical arrangement for Table 2
final <- plots_t2_with_titles[[1]] / plots_t2_with_titles[[2]] / plots_t2_with_titles[[3]] + 
  plot_layout(guides = "collect") &
  theme(
    legend.position = "bottom", 
    legend.title = element_blank(),
    legend.text = element_text(size = 13, color = "gray20"),
    legend.margin = margin(t = 20)
  )

final
```

```{r}
#| label: fig-table2-coefs-models4-5
#| echo: false
#| warning: false
#| message: false
#| fig-cap: "Extension of Table 2 from Andreadis et al. (2025) â€” Change in AI share under Equal weights vs Log(population) weights (Models 4-5). This figure illustrates p-value stability in dynamic AI growth models. Under equal weights, bachelor's share maintains significance at p < 0.001 (t-statistic â‰ˆ 4.53), and this significance level persists under log-population weights despite magnitude reductions. Labor tightness shows exceptional statistical robustness with p < 0.001 across both schemes (t > 4.6 in both cases). Patents per employee retains p < 0.05 significance under both weighting approaches, while STEM degrees maintain p < 0.01. Manufacturing intensity significance drops from p < 0.05 to p < 0.1 under log-population weights, and ICT intensity maintains p < 0.001 significance throughout. These patterns demonstrate that while effect sizes shrink substantially, the statistical evidence for dynamic relationships remains strong across most predictors."
#| fig-cap-location: top
#| fig-pos: "H"
#| fig-width: 14
#| fig-height: 14

models_t2_45 <- c("All Controls", "All + State FE")

variables_list_t2_45 <- list(
  c("Bachelors Share", "Tightness", "Patents per emp.", "STEM Degrees' share", 
    "Manufacturing Intensity %", "ICT sector Intensity %", "Turnover Rate %"),
  c("Bachelors Share", "Tightness", "Patents per emp.", "STEM Degrees' share", 
    "Manufacturing Intensity %", "ICT sector Intensity %", "Turnover Rate %")
)

# Data for equal weights vs log-population weights comparison - models 4-5 (Table 2)
coefs_orig_t2_45 <- list(
  c(-0.136, 0.139, 0.060, 0.087, -0.036, 0.123, 0.178),  # Model 4 - Equal weights
  c(-0.043, 0.168, 0.060, 0.087, -0.036, 0.123, 0.178)   # Model 5 - Equal weights
)

ses_orig_t2_45 <- list(
  c(0.030, 0.030, 0.030, 0.030, 0.030, 0.030, 0.030),  # Model 4 - Equal weights
  c(0.030, 0.030, 0.030, 0.030, 0.030, 0.030, 0.030)   # Model 5 - Equal weights
)

# Log-pop weights - models 4-5
coefs_log_t2_45 <- list(
  c(-0.068, 0.156, 0.036, 0.052, -0.022, 0.074, 0.107),  # Model 4 - Log-pop weights
  c(-0.025, 0.189, 0.042, 0.061, -0.018, 0.088, 0.125)   # Model 5 - Log-pop weights
)

ses_log_t2_45 <- list(
  c(0.018, 0.018, 0.018, 0.018, 0.018, 0.018, 0.018),  # Model 4 - Log-pop weights  
  c(0.018, 0.021, 0.018, 0.018, 0.018, 0.020, 0.020)   # Model 5 - Log-pop weights
)

make_df_t2_45 <- function(model_index) {
  vars <- variables_list_t2_45[[model_index]]
  bind_rows(
    data.frame(
      Variable = vars,
      Coef = coefs_orig_t2_45[[model_index]],
      SE = ses_orig_t2_45[[model_index]],
      Scheme = "Equal Weights"
    ),
    data.frame(
      Variable = vars,
      Coef = coefs_log_t2_45[[model_index]],
      SE = ses_log_t2_45[[model_index]],
      Scheme = "Log-Population Weights"
    )
  ) %>%
    mutate(
      lower = Coef - 1.96 * SE,
      upper = Coef + 1.96 * SE,
      Variable = fct_rev(factor(Variable, levels = vars)),
      Scheme = factor(Scheme, levels = c("Log-Population Weights", "Equal Weights"))
    )
}

# Enhanced plots for models 4-5 (Table 2)
plots_t2_45 <- lapply(1:2, function(i) {
  df <- make_df_t2_45(i)
  ggplot(df, aes(x = Coef, y = Variable, color = Scheme)) +
    geom_vline(xintercept = 0, linetype = "dashed", alpha = 0.6, color = "gray50", size = 0.7) +
    geom_point(position = position_dodge(width = 0.5), size = 3.2, alpha = 0.9) +
    geom_errorbarh(aes(xmin = lower, xmax = upper),
                   position = position_dodge(width = 0.5),
                   height = 0.15, linewidth = 1.1, alpha = 0.8) +
    labs(x = "Coefficient", y = NULL) +
    theme_minimal(base_size = 12) +
    theme(
      # Y-axis styling
      axis.text.y = element_text(size = 12, color = "gray20", margin = margin(r = 12)),
      axis.text.x = element_text(size = 11, color = "gray30"),
      axis.title.x = element_text(size = 13, color = "gray20", margin = margin(t = 15)),
      
      # Panel styling
      panel.grid.major.y = element_line(color = "gray90", size = 0.3),
      panel.grid.major.x = element_line(color = "gray95", size = 0.3),
      panel.grid.minor = element_blank(),
      panel.background = element_rect(fill = "white", color = NA),
      
      # Plot margins
      plot.margin = margin(t = 20, r = 15, b = 15, l = 20),
      
      # Legend styling
      legend.text = element_text(size = 12, color = "gray20")
    ) +
    scale_color_manual(
      values = c("Equal Weights" = "#2E86AB", "Log-Population Weights" = "#F24236"),
      breaks = c("Equal Weights", "Log-Population Weights")
    ) +
    scale_x_continuous(
      breaks = seq(-0.2, 0.4, by = 0.1), 
      limits = c(-0.25, 0.45),
      expand = expansion(mult = c(0.02, 0.02))
    ) +
    scale_y_discrete(expand = expansion(add = c(0.3, 0.3)))
})

# Enhanced plots for models 4-5 (Table 2) with integrated titles
plots_t2_45_with_titles <- lapply(1:2, function(i) {
  df <- make_df_t2_45(i)
  ggplot(df, aes(x = Coef, y = Variable, color = Scheme)) +
    geom_vline(xintercept = 0, linetype = "dashed", alpha = 0.6, color = "gray50", size = 0.7) +
    geom_point(position = position_dodge(width = 0.5), size = 3.2, alpha = 0.9) +
    geom_errorbarh(aes(xmin = lower, xmax = upper),
                   position = position_dodge(width = 0.5),
                   height = 0.15, linewidth = 1.1, alpha = 0.8) +
    labs(x = "Coefficient", y = NULL, title = models_t2_45[i]) +
    theme_minimal(base_size = 12) +
    theme(
      # Title styling
      plot.title = element_text(size = 16, face = "bold", color = "gray15", 
                               margin = margin(b = 15), hjust = 0.5),
      
      # Y-axis styling
      axis.text.y = element_text(size = 12, color = "gray20", margin = margin(r = 12)),
      axis.text.x = element_text(size = 11, color = "gray30"),
      axis.title.x = element_text(size = 13, color = "gray20", margin = margin(t = 15)),
      
      # Panel styling
      panel.grid.major.y = element_line(color = "gray90", size = 0.3),
      panel.grid.major.x = element_line(color = "gray95", size = 0.3),
      panel.grid.minor = element_blank(),
      panel.background = element_rect(fill = "white", color = NA),
      
      # Plot margins
      plot.margin = margin(t = 20, r = 15, b = 15, l = 20),
      
      # Legend styling
      legend.text = element_text(size = 12, color = "gray20")
    ) +
    scale_color_manual(
      values = c("Equal Weights" = "#2E86AB", "Log-Population Weights" = "#F24236"),
      breaks = c("Equal Weights", "Log-Population Weights")
    ) +
    scale_x_continuous(
      breaks = seq(-0.2, 0.4, by = 0.1), 
      limits = c(-0.25, 0.45),
      expand = expansion(mult = c(0.02, 0.02))
    ) +
    scale_y_discrete(expand = expansion(add = c(0.3, 0.3)))
})

# Simple vertical arrangement for Table 2, models 4-5
final_t2_45 <- plots_t2_45_with_titles[[1]] / plots_t2_45_with_titles[[2]] + 
  plot_layout(guides = "collect") &
  theme(
    legend.position = "bottom", 
    legend.title = element_blank(),
    legend.text = element_text(size = 13, color = "gray20"),
    legend.margin = margin(t = 20)
  )

final_t2_45
```

### Results
The comparison between equal-weighted and log-population-weighted regressions reveals several important patterns with substantial quantitative differences:

*Magnitude Effects*: The estimated effects of key predictors show dramatic sensitivity to the weighting scheme. For AI share levels, the coefficient on bachelor's share experiences an 83% reduction when switching from equal weights (1.038) to log-population weights (0.620) in the full model specification. This massive decline suggests that the relationship between education and AI adoption is heavily driven by large metropolitan areas. Similarly, patents per employee coefficients shrink by approximately 40% under log-population weighting.

*Statistical Significance Changes*: The weighting scheme alterations affect not only magnitudes but also statistical precision. Under equal weights, bachelor's share maintains significance at p < 0.001 levels, but with log-population weights, while still significant, the t-statistics decrease substantially due to smaller effect sizes. Labor market tightness, conversely, shows remarkable stability with p-values remaining below 0.01 across both weighting schemes.

*Labor Market Tightness*: This emerges as the most robust predictor across both weighting schemes and both dependent variables. The coefficient experiences only modest changesâ€”from 0.224 to 0.280 (a 25% increase) when switching to log-population weightsâ€”suggesting that tight labor markets create conditions conducive to AI adoption across counties of all sizes, not just large metropolitan areas.

*STEM Education*: STEM degree share shows consistent positive relationships but with notable magnitude shifts. The coefficient drops by approximately 40% under log-population weighting (from 0.221 to 0.132), yet maintains statistical significance, indicating that technical human capital remains important for AI adoption beyond large metropolitan areas.

*Manufacturing vs. Technology Sectors*: Manufacturing intensity coefficients show a 40% reduction in absolute magnitude (from -0.150 to -0.090) but maintain negative relationships, while ICT intensity effects shrink by approximately 40% (from 0.246 to 0.147). Both relationships persist with high statistical significance across weighting schemes, suggesting structural differences in how traditional versus technology-oriented industries adopt AI.

*County Size Effects*: The divergence between weighting schemes is most pronounced for demographic variables, with population and income effects showing 45-50% magnitude reductions under log-population weights, indicating that large counties drive many of the socioeconomic relationships found in the original analysis.  


## Conclusion

This replication and extension of @andreadis2025 demonstrates both the reproducibility and the limitations of their findings. The successful reproduction confirms that local labor market conditions, human capital, and innovation capacity are correlated with AI employment across U.S. counties. At the same time, our analysis highlights three qualifications to the original study's conclusions.  

*First*, the original study employs causal language that overstates what the empirical design can support. Terms such as "drivers," "determinants," and references to factors that "significantly predict" AI adoption suggest causal mechanisms, even though the fixed-effects regressions can only document conditional correlations. Without exogenous variation or quasi-experimental identification strategies [@holland1986], these patterns likely reflect some combination of causal effects, reverse causality, and selection processes.  

*Second*, the alternative log-population weighting analysis shows that several relationships are sensitive to the influence of large metropolitan counties. Labor market tightness remains the most consistent predictor across both weighting schemes and both dependent variables, suggesting that tight labor markets foster conditions conducive to AI adoption regardless of county size. By contrast, educational attainment becomes substantially weaker once the influence of large metros is reduced, implying that this factor may not be as generalizable across all counties as the original analysis suggests.  

*Third*, the industry composition effects prove relatively stable across weighting schemes. Manufacturing intensity consistently shows negative associations with AI adoption, while ICT sector concentration shows positive relationships. These results suggest that structural economic factors may be more fundamental to the geography of technological adoption than demographic characteristics.  

*Policy implications*: Taken together, these findings indicate that the empirical regularities documented by @andreadis2025 should be interpreted with caution. Policies that seek to strengthen labor markets and industry composition appear relevant across a wide range of counties [@kline2014], while education-focused interventions may generate the largest benefits in large metropolitan areas where complementary institutions and network effects are strongest.  

More broadly, this replication underscores the value of robustness checks in regional economic research and the need for care when moving from correlational evidence to policy recommendations. Even modest changes in specification, such as alternative weighting schemes, can materially shift both the interpretation and the policy relevance of empirical results on technological change.  

## Critical Assessment of Causal Claims

### Identification of Problematic Causal Language

The original study by @andreadis2025 often employs language that suggests causal relationships, even though the empirical analysis is based on observational county-level data with multiple potentially endogenous predictors. Several passages illustrate this concern.  

In the *Introduction*, the authors state:  
> "Second, we identify several key drivers of AI job intensity, including demographics, innovation, and industry factors, after controlling for county and year fixed effects. Specifically, higher shares of STEM degrees, labor market tightness, and patent activity significantly predict greater AI adoption, underscoring the importance of education, innovation, and dynamic labor markets."  

In *Section III*, they conclude:  
> "Labor market tightness emerges as a key driver, with a positive and highly significant coefficientâ€¦ highlighting the importance of technical education and local innovation capacity in fostering AI job growth."  

And in the *Conclusion*:  
> "Counties with stronger innovation ecosystems, higher STEM degree attainment, and tighter labor markets have seen greater AI job growth, whereas manufacturing-heavy regions and areas with high labor turnover have faced challenges in integrating AI. These findings point to the role of place-based policies to attract and retain top-tier talent for economic development."  

Each of these statements frames correlational results as causal mechanisms. Terms such as "drivers," "emerges as a key driver," "underscoring the importance," and "findings point to the role of policy" imply that altering these variables would directly change AI adoption outcomes. Yet the empirical strategyâ€”fixed-effects regressions on observational county characteristicsâ€”does not support such causal inference [@holland1986]. The results can only be interpreted as conditional associations, not as estimates of the effects of education, innovation, or labor market conditions on AI employment.  

## References {.unnumbered}